{"posts":[{"title":"test","content":"func main() { t1 := T{1} //t2 := &amp;t1 //fmt.Printf(&quot;t2 is : %v\\n&quot;, t2) t1.testT() fmt.Printf(&quot;t2 is : %v\\n&quot;, t1) t1.testP() fmt.Printf(&quot;t2 is : %v\\n&quot;, t1) } func IsInSlice(value interface{}, sli interface{}) bool { switch reflect.TypeOf(sli).Kind() { case reflect.Slice, reflect.Array: s := reflect.ValueOf(sli) for i := 0; i &lt; s.Len(); i++ { if reflect.DeepEqual(value, s.Index(i).Interface()) { return true } } } return false } func worker(stopCh &lt;-chan struct{}) { go func() { defer fmt.Println(&quot;worker exit&quot;) // Using stop channel explicit exit for { select { case &lt;-stopCh: fmt.Println(&quot;Recv stop signal&quot;) return case &lt;-t.C: fmt.Println(&quot;Working .&quot;) } } }() return } ","link":"https://ChicRingo.github.io/post/test/"},{"title":"Go 每日一库之 jobrunner","content":" 简介 我们在 Web 开发中时常会遇到这样的需求，执行一个操作之后，需要给用户一定形式的通知。例如，用户下单之后通过邮件发送电子发票，网上购票支付后通过短信发送车次信息。但是这类需求并不需要非常及时，如果放在请求流程中处理，会影响请求的响应时间。这类任务我们一般使用异步的方式来执行。jobrunner就是其中一个用来执行异步任务的 Go 语言库。得益于强大的cron库，再搭配jobrunner的任务状态监控，jobrunner非常易于使用。 快速使用 本文使用 Go Modules。 创建目录并初始化： $ mkdir jobrunner &amp;&amp; cd jobrunner $ go mod init github.com/darjun/go-daily-lib/jobrunner 安装jobrunner： $ go get -u github.com/bamzi/jobrunner 使用： package main import ( &quot;fmt&quot; &quot;time&quot; &quot;github.com/bamzi/jobrunner&quot; ) type GreetingJob struct { Name string } func (g GreetingJob) Run() { fmt.Println(&quot;Hello, &quot;, g.Name) } func main() { jobrunner.Start() jobrunner.Schedule(&quot;@every 5s&quot;, GreetingJob{Name: &quot;dj&quot;}) time.Sleep(10 * time.Second) } 我们创建一个任务，每隔 5s 打印一条欢迎信息。任务的创建和执行与cron完全相同，详细使用见我前面的一篇博文。 注意，jobrunner需要先Start()，然后再添加任务。因为在Start()中创建MainCron对象，先添加任务会panic！！！ 注意main函数尾的time.Sleep(10 * time.Second)，因为主 goroutine 结束之后整个程序就退出了，jobrunner中的任务就没有机会被执行了。加上time.Sleep是为了让大家能看到输出，实际使用中不会这样做。 与 web 框架整合 jobrunner能很方便地与当前常见的 Web 框架整合，如Gin/Echo/Martini/Beego/Revel等。下面通过一个简单的例子演示如何在 Gin 中使用jobrunner：用户登录时给他的邮箱发送一封邮件。 首先需要安装相应的库： $ go get -u github.com/gin-gonic/gin $ github.com/jordan-wright/email 编写代码： package main import ( &quot;fmt&quot; &quot;net/smtp&quot; &quot;time&quot; &quot;github.com/bamzi/jobrunner&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/jordan-wright/email&quot; ) type EmailJob struct { Name string Email string } type User struct { Name string `form:&quot;name&quot;` Email string `form:&quot;email&quot;` } func (j EmailJob) Run() { e := email.NewEmail() e.From = &quot;leedarjun@126.com&quot; e.To = []string{j.Email} e.Cc = []string{&quot;leedarjun@126.com&quot;} e.Subject = &quot;Welcome To Awesome-Web&quot; e.Text = []byte(fmt.Sprintf(` Hello, %s Welcome Back `, j.Name)) err := e.Send(&quot;smtp.126.com:25&quot;, smtp.PlainAuth(&quot;&quot;, &quot;leedarjun@126.com&quot;, &quot;yyyyyy&quot;, &quot;smtp.126.com&quot;)) if err != nil { fmt.Printf(&quot;failed to send email to %s, err:%v&quot;, j.Name, err) } } func login(c *gin.Context) { var u User if c.ShouldBind(&amp;u) == nil { c.String(200, &quot;login success&quot;) jobrunner.In(5*time.Second, EmailJob{Name: u.Name, Email: u.Email}) } else { c.String(404, &quot;login failed&quot;) } } func main() { r := gin.Default() r.GET(&quot;/login&quot;, login) r.Run(&quot;:8888&quot;) } 这里只是为了简单演示，我们编写了一个简陋的login函数处理登录，传入name和email，然后给该email发送邮件。email库的详细使用可以查看我之前的博文了解。 只需要在浏览器中输入http://localhost:8888/login?name=dj&amp;email=935653229@qq.com，我的 QQ 邮箱就能收到邮件： 监控 jobrunner内置了一个监控模块，可以很方便地通过网页或者 API 获取当前的任务状态数据： package main import ( &quot;fmt&quot; &quot;html/template&quot; &quot;os&quot; &quot;time&quot; &quot;github.com/bamzi/jobrunner&quot; &quot;github.com/gin-gonic/gin&quot; ) type GreetingJob struct { Name string } func (g GreetingJob) Run() { fmt.Println(&quot;Hello,&quot;, g.Name) } type EmailJob struct { Email string } func (e EmailJob) Run() { fmt.Println(&quot;Send,&quot;, e.Email) } func main() { r := gin.Default() jobrunner.Start() jobrunner.Every(5*time.Second, GreetingJob{Name: &quot;dj&quot;}) jobrunner.Every(10*time.Second, EmailJob{Email: &quot;935653229@qq.com&quot;}) r.GET(&quot;/jobrunner/json&quot;, JobJson) r.GET(&quot;/jobrunner/html&quot;, JobHtml) r.Run(&quot;:8888&quot;) } func JobJson(c *gin.Context) { c.JSON(200, jobrunner.StatusJson()) } func JobHtml(c *gin.Context) { t, err := template.ParseFiles(os.Getenv(&quot;GOPATH&quot;) + &quot;/src/github.com/bamzi/jobrunner/views/Status.html&quot;) if err != nil { c.JSON(400, &quot;error&quot;) } t.Execute(c.Writer, jobrunner.StatusPage()) } 运行之后，在浏览器中输入http://localhost:8888/jobrunner/html查看任务状态： 这里显示任务名、任务 ID、状态、上次运行时间、下次运行时间以及处理延迟。 我们还可以通过http://localhost:8888/jobrunner/json获取原始 JSON 格式的数据自己处理： 总结 大家如果发现好玩、好用的 Go 语言库，欢迎到 Go 每日一库 GitHub 上提交 issue😄 参考 jobrunner GitHub：https://github.com/bamzi/jobrunner Go 每日一库 GitHub：https://github.com/darjun/go-daily-lib ","link":"https://ChicRingo.github.io/post/go-mei-ri-yi-ku-zhi-jobrunner/"},{"title":"利用Go反射机制实现判断slice中是否存在某个item","content":"为什么需要？ 日常开发过程中经常遇到需要判断某个 slice(或者 array)中是否包含某个 item 的情况，比如判断 10 是否在[]int{1,2,3}中 怎么做？ 一般最容易想到的方法是遍历 slice 中的每个元素，直到找到了该元素，否则返回 false，如下： package main func IsInSlice(value int, sli []int) bool { for _, v := range sli { if value == v { return true } } return false } 这种方法实现略显笨拙，并且针对不同的数据类型无法通用，如果有不同的数据类型，则容易生成很多相同功能的函数，只是参数不同，这样的话代码可用性并不高。 如何改进 golang 中可以通过 reflect 包中的 TypeOf(), ValueOf()和 DeepEqual()接口对方法进行改进，方法参数使用 interface{}类型，代码实现如下： package main import &quot;reflect&quot; func IsInSlice(value interface{}, sli interface{}) bool { switch reflect.TypeOf(sli).Kind() { case reflect.Slice, reflect.Array: s := reflect.ValueOf(sli) for i := 0; i &lt; s.Len(); i++ { if reflect.DeepEqual(value, s.Index(i).Interface()) { return true } } } return false } 瞬间不用再为不同数据类型需要写不同函数而心烦了！ 提示 因为反射需要的时间开销比较大，所以通用写法的效率肯定比特定类型的写法低，所以需要根据实际情况来权衡使用，如下截图为 int 类型的基准测试： 原文作者：pyihe 原文链接：https://pyihe.github.io/2020/05/29/Golang%E5%88%A4%E6%96%ADslice%E4%B8%AD%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E6%9F%90%E4%B8%AAitem.html ","link":"https://ChicRingo.github.io/post/li-yong-go-fan-she-ji-zhi-shi-xian-pan-duan-slice-zhong-shi-fou-cun-zai-mou-ge-item/"},{"title":"使用Go实现GoF的23种设计模式（二）","content":"作者：元闰子 链接：https://juejin.im/post/6864011017384132621 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 前言 上一篇文章《使用Go实现GoF的23种设计模式（一）》介绍了23种设计模式中的创建型模式（Creational Pattern），创建型模式是处理对象创建的一类设计模式，主要思想是向对象的使用者隐藏对象创建的具体细节，从而达到解耦的目的。本文主要聚焦在结构型模式（Structural Pattern）上，其主要思想是将多个对象组装成较大的结构，并同时保持结构的灵活和高效，从程序的结构上解决模块之间的耦合问题。 组合模式（Composite Pattern） 简述 在面向对象编程中，有两个常见的对象设计方法，组合和继承，两者都可以解决代码复用的问题，但是使用后者时容易出现继承层次过深，对象关系过于复杂的副作用，从而导致代码的可维护性变差。因此，一个经典的面向对象设计原则是：组合优于继承。 我们都知道，组合所表示的语义为“has-a”，也就是部分和整体的关系，最经典的组合模式描述如下： 将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 Go语言天然就支持了组合模式，而且从它不支持继承关系的特点来看，Go也奉行了组合优于继承的原则，鼓励大家在进行程序设计时多采用组合的方法。Go实现组合模式的方式有两种，分别是直接组合（Direct Composition）和嵌入组合（Embedding Composition），下面我们一起探讨这两种不同的实现方法。 Go实现 直接组合（Direct Composition）的实现方式类似于Java/C++，就是将一个对象作为另一个对象的成员属性。 一个典型的实现如《使用Go实现GoF的23种设计模式（一）》中所举的例子，一个Message结构体，由Header和Body所组成。那么Message就是一个整体，而Header和Body则为消息的组成部分。 type Message struct { Header *Header Body *Body } 复制代码 现在，我们来看一个稍微复杂一点的例子，同样考虑上一篇文章中所描述的插件架构风格的消息处理系统。前面我们用抽象工厂模式解决了插件加载的问题，通常，每个插件都会有一个生命周期，常见的就是启动状态和停止状态，现在我们使用组合模式来解决插件的启动和停止问题。 首先给Plugin接口添加几个生命周期相关的方法： package plugin ... // 插件运行状态 type Status uint8 const ( Stopped Status = iota Started ) type Plugin interface { // 启动插件 Start() // 停止插件 Stop() // 返回插件当前的运行状态 Status() Status } // Input、Filter、Output三类插件接口的定义跟上一篇文章类似 // 这里使用Message结构体替代了原来的string，使得语义更清晰 type Input interface { Plugin Receive() *msg.Message } type Filter interface { Plugin Process(msg *msg.Message) *msg.Message } type Output interface { Plugin Send(msg *msg.Message) } 复制代码 对于插件化的消息处理系统而言，一切皆是插件，因此我们将Pipeine也设计成一个插件，实现Plugin接口： package pipeline ... // 一个Pipeline由input、filter、output三个Plugin组成 type Pipeline struct { status plugin.Status input plugin.Input filter plugin.Filter output plugin.Output } func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } // 启动的顺序 output -&gt; filter -&gt; input func (p *Pipeline) Start() { p.output.Start() p.filter.Start() p.input.Start() p.status = plugin.Started fmt.Println(&quot;Hello input plugin started.&quot;) } // 停止的顺序 input -&gt; filter -&gt; output func (p *Pipeline) Stop() { p.input.Stop() p.filter.Stop() p.output.Stop() p.status = plugin.Stopped fmt.Println(&quot;Hello input plugin stopped.&quot;) } func (p *Pipeline) Status() plugin.Status { return p.status } 复制代码 一个Pipeline由Input、Filter、Output三类插件组成，形成了“部分-整体”的关系，而且它们都实现了Plugin接口，这就是一个典型的组合模式的实现。Client无需显式地启动和停止Input、Filter和Output插件，在调用Pipeline对象的Start和Stop方法时，Pipeline就已经帮你按顺序完成对应插件的启动和停止。 相比于上一篇文章，在本文中实现Input、Filter、Output三类插件时，需要多实现3个生命周期的方法。还是以上一篇文章中的HelloInput、UpperFilter和ConsoleOutput作为例子，具体实现如下： package plugin ... type HelloInput struct { status Status } func (h *HelloInput) Receive() *msg.Message { // 如果插件未启动，则返回nil if h.status != Started { fmt.Println(&quot;Hello input plugin is not running, input nothing.&quot;) return nil } return msg.Builder(). WithHeaderItem(&quot;content&quot;, &quot;text&quot;). WithBodyItem(&quot;Hello World&quot;). Build() } func (h *HelloInput) Start() { h.status = Started fmt.Println(&quot;Hello input plugin started.&quot;) } func (h *HelloInput) Stop() { h.status = Stopped fmt.Println(&quot;Hello input plugin stopped.&quot;) } func (h *HelloInput) Status() Status { return h.status } 复制代码 package plugin ... type UpperFilter struct { status Status } func (u *UpperFilter) Process(msg *msg.Message) *msg.Message { if u.status != Started { fmt.Println(&quot;Upper filter plugin is not running, filter nothing.&quot;) return msg } for i, val := range msg.Body.Items { msg.Body.Items[i] = strings.ToUpper(val) } return msg } func (u *UpperFilter) Start() { u.status = Started fmt.Println(&quot;Upper filter plugin started.&quot;) } func (u *UpperFilter) Stop() { u.status = Stopped fmt.Println(&quot;Upper filter plugin stopped.&quot;) } func (u *UpperFilter) Status() Status { return u.status } 复制代码 package plugin ... type ConsoleOutput struct { status Status } func (c *ConsoleOutput) Send(msg *msg.Message) { if c.status != Started { fmt.Println(&quot;Console output is not running, output nothing.&quot;) return } fmt.Printf(&quot;Output:\\n\\tHeader:%+v, Body:%+v\\n&quot;, msg.Header.Items, msg.Body.Items) } func (c *ConsoleOutput) Start() { c.status = Started fmt.Println(&quot;Console output plugin started.&quot;) } func (c *ConsoleOutput) Stop() { c.status = Stopped fmt.Println(&quot;Console output plugin stopped.&quot;) } func (c *ConsoleOutput) Status() Status { return c.status } 复制代码 测试代码如下： package test ... func TestPipeline(t *testing.T) { p := pipeline.Of(pipeline.DefaultConfig()) p.Start() p.Exec() p.Stop() } // 运行结果 === RUN TestPipeline Console output plugin started. Upper filter plugin started. Hello input plugin started. Pipeline started. Output: Header:map[content:text], Body:[HELLO WORLD] Hello input plugin stopped. Upper filter plugin stopped. Console output plugin stopped. Hello input plugin stopped. --- PASS: TestPipeline (0.00s) PASS 复制代码 组合模式的另一种实现，嵌入组合（Embedding Composition），其实就是利用了Go语言的匿名成员特性，本质上跟直接组合是一致的。 还是以Message结构体为例，如果采用嵌入组合，则看起来像是这样： type Message struct { Header Body } // 使用时，Message可以引用Header和Body的成员属性，例如： msg := &amp;Message{} msg.SrcAddr = &quot;192.168.0.1&quot; 复制代码 适配器模式（Adapter Pattern） 简述 适配器模式是最常用的结构型模式之一，它让原本因为接口不匹配而无法一起工作的两个对象能够一起工作。在现实生活中，适配器模式也是处处可见，比如电源插头转换器，可以让英式的插头工作在中式的插座上。适配器模式所做的就是将一个接口Adaptee，通过适配器Adapter转换成Client所期望的另一个接口Target来使用，实现原理也很简单，就是Adapter通过实现Target接口，并在对应的方法中调用Adaptee的接口实现。 一个典型的应用场景是，系统中一个老的接口已经过时即将废弃，但因为历史包袱没法立即将老接口全部替换为新接口，这时可以新增一个适配器，将老的接口适配成新的接口来使用。适配器模式很好的践行了面向对象设计原则里的开闭原则（open/closed principle），新增一个接口时也无需修改老接口，只需多加一个适配层即可。 Go实现 继续考虑上一节的消息处理系统例子，目前为止，系统的输入都源自于HelloInput，现在假设需要给系统新增从Kafka消息队列中接收数据的功能，其中Kafka消费者的接口如下： package kafka ... type Records struct { Items []string } type Consumer interface { Poll() Records } 复制代码 由于当前Pipeline的设计是通过plugin.Input接口来进行数据接收，因此kafka.Consumer并不能直接集成到系统中。 怎么办？使用适配器模式！ 为了能让Pipeline能够使用kafka.Consumer接口，我们需要定义一个适配器如下： package plugin ... type KafkaInput struct { status Status consumer kafka.Consumer } func (k *KafkaInput) Receive() *msg.Message { records := k.consumer.Poll() if k.status != Started { fmt.Println(&quot;Kafka input plugin is not running, input nothing.&quot;) return nil } return msg.Builder(). WithHeaderItem(&quot;content&quot;, &quot;kafka&quot;). WithBodyItems(records.Items). Build() } // 在输入插件映射关系中加入kafka，用于通过反射创建input对象 func init() { inputNames[&quot;hello&quot;] = reflect.TypeOf(HelloInput{}) inputNames[&quot;kafka&quot;] = reflect.TypeOf(KafkaInput{}) } ... 复制代码 因为Go语言并没有构造函数，如果按照上一篇文章中的抽象工厂模式来创建KafkaInput，那么得到的实例中的consumer成员因为没有被初始化而会是nil。因此，需要给Plugin接口新增一个Init方法，用于定义插件的一些初始化操作，并在工厂返回实例前调用。 package plugin ... type Plugin interface { Start() Stop() Status() Status // 新增初始化方法，在插件工厂返回实例前调用 Init() } // 修改后的插件工厂实现如下 func (i *InputFactory) Create(conf Config) Plugin { t, _ := inputNames[conf.Name] p := reflect.New(t).Interface().(Plugin) // 返回插件实例前调用Init函数，完成相关初始化方法 p.Init() return p } // KakkaInput的Init函数实现 func (k *KafkaInput) Init() { k.consumer = &amp;kafka.MockConsumer{} } 复制代码 上述代码中的kafka.MockConsumer为我们模式Kafka消费者的一个实现，代码如下： package kafka ... type MockConsumer struct {} func (m *MockConsumer) Poll() *Records { records := &amp;Records{} records.Items = append(records.Items, &quot;i am mock consumer.&quot;) return records } 复制代码 测试代码如下： package test ... func TestKafkaInputPipeline(t *testing.T) { config := pipeline.Config{ Name: &quot;pipeline2&quot;, Input: plugin.Config{ PluginType: plugin.InputType, Name: &quot;kafka&quot;, }, Filter: plugin.Config{ PluginType: plugin.FilterType, Name: &quot;upper&quot;, }, Output: plugin.Config{ PluginType: plugin.OutputType, Name: &quot;console&quot;, }, } p := pipeline.Of(config) p.Start() p.Exec() p.Stop() } // 运行结果 === RUN TestKafkaInputPipeline Console output plugin started. Upper filter plugin started. Kafka input plugin started. Pipeline started. Output: Header:map[content:kafka], Body:[I AM MOCK CONSUMER.] Kafka input plugin stopped. Upper filter plugin stopped. Console output plugin stopped. Pipeline stopped. --- PASS: TestKafkaInputPipeline (0.00s) PASS 复制代码 桥接模式（Bridge Pattern） 简述 桥接模式主要用于将抽象部分和实现部分进行解耦，使得它们能够各自往独立的方向变化。它解决了在模块有多种变化方向的情况下，用继承所导致的类爆炸问题。举一个例子，一个产品有形状和颜色两个特征（变化方向），其中形状分为方形和圆形，颜色分为红色和蓝色。如果采用继承的设计方案，那么就需要新增4个产品子类：方形红色、圆形红色、方形蓝色、圆形红色。如果形状总共有m种变化，颜色有n种变化，那么就需要新增m*n个产品子类！现在我们使用桥接模式进行优化，将形状和颜色分别设计为一个抽象接口独立出来，这样需要新增2个形状子类：方形和圆形，以及2个颜色子类：红色和蓝色。同样，如果形状总共有m种变化，颜色有n种变化，总共只需要新增m+n个子类！ 上述例子中，我们通过将形状和颜色抽象为一个接口，使产品不再依赖于具体的形状和颜色细节，从而达到了解耦的目的。桥接模式本质上就是面向接口编程，可以给系统带来很好的灵活性和可扩展性。如果一个对象存在多个变化的方向，而且每个变化方向都需要扩展，那么使用桥接模式进行设计那是再合适不过了。 Go实现 回到消息处理系统的例子，一个Pipeline对象主要由Input、Filter、Output三类插件组成（3个特征），因为是插件化的系统，不可避免的就要求支持多种Input、Filter、Output的实现，并能够灵活组合（有多个变化的方向）。显然，Pipeline就非常适合使用桥接模式进行设计，实际上我们也这么做了。我们将Input、Filter、Output分别设计成一个抽象的接口，它们按照各自的方向去扩展。Pipeline只依赖的这3个抽象接口，并不感知具体实现的细节。 package plugin ... type Input interface { Plugin Receive() *msg.Message } type Filter interface { Plugin Process(msg *msg.Message) *msg.Message } type Output interface { Plugin Send(msg *msg.Message) } 复制代码 package pipeline ... // 一个Pipeline由input、filter、output三个Plugin组成 type Pipeline struct { status plugin.Status input plugin.Input filter plugin.Filter output plugin.Output } // 通过抽象接口来使用，看不到底层的实现细节 func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } 复制代码 测试代码如下： package test ... func TestPipeline(t *testing.T) { p := pipeline.Of(pipeline.DefaultConfig()) p.Start() p.Exec() p.Stop() } // 运行结果 === RUN TestPipeline Console output plugin started. Upper filter plugin started. Hello input plugin started. Pipeline started. Output: Header:map[content:text], Body:[HELLO WORLD] Hello input plugin stopped. Upper filter plugin stopped. Console output plugin stopped. Pipeline stopped. --- PASS: TestPipeline (0.00s) PASS 复制代码 总结 本文主要介绍了结构型模式中的组合模式、适配器模式和桥接模式。组合模式主要解决代码复用的问题，相比于继承关系，组合模式可以避免继承层次过深导致的代码复杂问题，因此面向对象设计领域流传着组合优于继承的原则，而Go语言的设计也很好实践了该原则；适配器模式可以看作是两个不兼容接口之间的桥梁，可以将一个接口转换成Client所希望的另外一个接口，解决了模块之间因为接口不兼容而无法一起工作的问题；桥接模式将模块的抽象部分和实现部分进行分离，让它们能够往各自的方向扩展，从而达到解耦的目的。 下一篇文章，我们将继续聚焦于结构型模式，介绍完剩余的4种结模式：装饰模式、外观模式、享元模式和代理模式。 ","link":"https://ChicRingo.github.io/post/shi-yong-go-shi-xian-gof-de-23-chong-she-ji-mo-shi-er/"},{"title":"使用Go实现GoF的23种设计模式（一）","content":"作者：元闰子 链接：https://juejin.im/post/6859015515344633863 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 前言 从1995年GoF提出23种设计模式到现在，25年过去了，设计模式依旧是软件领域的热门话题。在当下，如果你不会一点设计模式，都不好意思说自己是一个合格的程序员。设计模式通常被定义为： 设计模式（Design Pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人理解并且保证代码可靠性。 从定义上看，设计模式其实是一种经验的总结，是针对特定问题的简洁而优雅的解决方案。既然是经验总结，那么学习设计模式最直接的好处就在于可以站在巨人的肩膀上解决软件开发过程中的一些特定问题。然而，学习设计模式的最高境界是习得其中解决问题所用到的思想，当你把它们的本质思想吃透了，也就能做到即使已经忘掉某个设计模式的名称和结构，也能在解决特定问题时信手拈来。 好的东西有人吹捧，当然也会招黑。设计模式被抨击主要因为以下两点： 1、设计模式会增加代码量，把程序逻辑变得复杂。这一点是不可避免的，但是我们并不能仅仅只考虑开发阶段的成本。最简单的程序当然是一个函数从头写到尾，但是这样后期的维护成本会变得非常大；而设计模式虽然增加了一点开发成本，但是能让人们写出可复用、可维护性高的程序。引用《软件设计的哲学》里的概念，前者就是战术编程，后者就是战略编程，我们应该对战术编程Say No！（请移步《一步步降低软件复杂性》） 2、滥用设计模式。这是初学者最容易犯的错误，当学到一个模式时，恨不得在所有的代码都用上，从而在不该使用模式的地方刻意地使用了模式，导致了程序变得异常复杂。其实每个设计模式都有几个关键要素：适用场景、解决方法、优缺点。模式并不是万能药，它只有在特定的问题上才能显现出效果。所以，在使用一个模式前，先问问自己，当前的这个场景适用这个模式吗？ 《设计模式》一书的副标题是“可复用面向对象软件的基础”，但并不意味着只有面向对象语言才能使用设计模式。模式只是一种解决特定问题的思想，跟语言无关。就像Go语言一样，它并非是像C++和Java一样的面向对象语言，但是设计模式同样适用。本系列文章将使用Go语言来实现GoF提出的23种设计模式，按照创建型模式（Creational Pattern）、结构型模式（Structural Pattern）和行为型模式（Behavioral Pattern）三种类别进行组织，文本主要介绍其中的创建型模式。 单例模式（Singleton Pattern） 简述 单例模式算是23中设计模式里最简单的一个了，它主要用于保证一个类仅有一个实例，并提供一个访问它的全局访问点。 在程序设计中，有一些对象通常我们只需要一个共享的实例，比如线程池、全局缓存、对象池等，这种场景下就适合使用单例模式。 但是，并非所有全局唯一的场景都适合使用单例模式。比如，考虑需要统计一个API调用的情况，有两个指标，成功调用次数和失败调用次数。这两个指标都是全局唯一的，所以有人可能会将其建模成两个单例SuccessApiMetric和FailApiMetric。按照这个思路，随着指标数量的增多，你会发现代码里类的定义会越来越多，也越来越臃肿。这也是单例模式最常见的误用场景，更好的方法是将两个指标设计成一个对象ApiMetric下的两个实例ApiMetic success和ApiMetic fail。 如何判断一个对象是否应该被建模成单例？ 通常，被建模成单例的对象都有“中心点”的含义，比如线程池就是管理所有线程的中心。所以，在判断一个对象是否适合单例模式时，先思考下，这个对象是一个中心点吗？ Go实现 在对某个对象实现单例模式时，有两个点必须要注意：（1）限制调用者直接实例化该对象；（2）为该对象的单例提供一个全局唯一的访问方法。 对于C++/Java而言，只需把类的构造函数设计成私有的，并提供一个static方法去访问该类点唯一实例即可。但对于Go语言来说，即没有构造函数的概念，也没有static方法，所以需要另寻出路。 我们可以利用Go语言package的访问规则来实现，将单例结构体设计成首字母小写，就能限定其访问范围只在当前package下，模拟了C++/Java中的私有构造函数；再在当前package下实现一个首字母大写的访问函数，就相当于static方法的作用了。 在实际开发中，我们经常会遇到需要频繁创建和销毁的对象。频繁的创建和销毁一则消耗CPU，二则内存的利用率也不高，通常我们都会使用对象池技术来进行优化。考虑我们需要实现一个消息对象池，因为是全局的中心点，管理所有的Message实例，所以将其实现成单例，实现代码如下： package msgpool ... // 消息池 type messagePool struct { pool *sync.Pool } // 消息池单例 var msgPool = &amp;messagePool{ // 如果消息池里没有消息，则新建一个Count值为0的Message实例 pool: &amp;sync.Pool{New: func() interface{} { return &amp;Message{Count: 0} }}, } // 访问消息池单例的唯一方法 func Instance() *messagePool { return msgPool } // 往消息池里添加消息 func (m *messagePool) AddMsg(msg *Message) { m.pool.Put(msg) } // 从消息池里获取消息 func (m *messagePool) GetMsg() *Message { return m.pool.Get().(*Message) } ... 复制代码 测试代码如下： package test ... func TestMessagePool(t *testing.T) { msg0 := msgpool.Instance().GetMsg() if msg0.Count != 0 { t.Errorf(&quot;expect msg count %d, but actual %d.&quot;, 0, msg0.Count) } msg0.Count = 1 msgpool.Instance().AddMsg(msg0) msg1 := msgpool.Instance().GetMsg() if msg1.Count != 1 { t.Errorf(&quot;expect msg count %d, but actual %d.&quot;, 1, msg1.Count) } } // 运行结果 === RUN TestMessagePool --- PASS: TestMessagePool (0.00s) PASS 复制代码 以上的单例模式就是典型的“饿汉模式”，实例在系统加载的时候就已经完成了初始化。对应地，还有一种“懒汉模式”，只有等到对象被使用的时候，才会去初始化它，从而一定程度上节省了内存。众所周知，“懒汉模式”会带来线程安全问题，可以通过普通加锁，或者更高效的双重检验锁来优化。对于“懒汉模式”，Go语言有一个更优雅的实现方式，那就是利用sync.Once，它有一个Do方法，其入参是一个方法，Go语言会保证仅仅只调用一次该方法。 // 单例模式的“懒汉模式”实现 package msgpool ... var once = &amp;sync.Once{} // 消息池单例，在首次调用时初始化 var msgPool *messagePool // 全局唯一获取消息池pool到方法 func Instance() *messagePool { // 在匿名函数中实现初始化逻辑，Go语言保证只会调用一次 once.Do(func() { msgPool = &amp;messagePool{ // 如果消息池里没有消息，则新建一个Count值为0的Message实例 pool: &amp;sync.Pool{New: func() interface{} { return &amp;Message{Count: 0} }}, } }) return msgPool } ... 复制代码 建造者模式（Builder Pattern） 简述 在程序设计中，我们会经常遇到一些复杂的对象，其中有很多成员属性，甚至嵌套着多个复杂的对象。这种情况下，创建这个复杂对象就会变得很繁琐。对于C++/Java而言，最常见的表现就是构造函数有着长长的参数列表： MyObject obj = new MyObject(param1, param2, param3, param4, param5, param6, ...) 复制代码 而对于Go语言来说，最常见的表现就是多层的嵌套实例化： obj := &amp;MyObject{ Field1: &amp;Field1 { Param1: &amp;Param1 { Val: 0, }, Param2: &amp;Param2 { Val: 1, }, ... }, Field2: &amp;Field2 { Param3: &amp;Param3 { Val: 2, }, ... }, ... } 复制代码 上述的对象创建方法有两个明显的缺点：（1）对对象使用者不友好，使用者在创建对象时需要知道的细节太多；（2）代码可读性很差。 针对这种对象成员较多，创建对象逻辑较为繁琐的场景，就适合使用建造者模式来进行优化。 建造者模式的作用有如下几个： 1、封装复杂对象的创建过程，使对象使用者不感知复杂的创建逻辑。 2、可以一步步按照顺序对成员进行赋值，或者创建嵌套对象，并最终完成目标对象的创建。 3、对多个对象复用同样的对象创建逻辑。 其中，第1和第2点比较常用，下面对建造者模式的实现也主要是针对这两点进行示例。 Go实现 考虑如下的一个Message结构体，其主要有Header和Body组成： package msg ... type Message struct { Header *Header Body *Body } type Header struct { SrcAddr string SrcPort uint64 DestAddr string DestPort uint64 Items map[string]string } type Body struct { Items []string } ... 复制代码 如果按照直接的对象创建方式，创建逻辑应该是这样的： // 多层的嵌套实例化 message := msg.Message{ Header: &amp;msg.Header{ SrcAddr: &quot;192.168.0.1&quot;, SrcPort: 1234, DestAddr: &quot;192.168.0.2&quot;, DestPort: 8080, Items: make(map[string]string), }, Body: &amp;msg.Body{ Items: make([]string, 0), }, } // 需要知道对象的实现细节 message.Header.Items[&quot;contents&quot;] = &quot;application/json&quot; message.Body.Items = append(message.Body.Items, &quot;record1&quot;) message.Body.Items = append(message.Body.Items, &quot;record2&quot;) 复制代码 虽然Message结构体嵌套的层次不多，但是从其创建的代码来看，确实存在对对象使用者不友好和代码可读性差的缺点。下面我们引入建造者模式对代码进行重构： package msg ... // Message对象的Builder对象 type builder struct { once *sync.Once msg *Message } // 返回Builder对象 func Builder() *builder { return &amp;builder{ once: &amp;sync.Once{}, msg: &amp;Message{Header: &amp;Header{}, Body: &amp;Body{}}, } } // 以下是对Message成员对构建方法 func (b *builder) WithSrcAddr(srcAddr string) *builder { b.msg.Header.SrcAddr = srcAddr return b } func (b *builder) WithSrcPort(srcPort uint64) *builder { b.msg.Header.SrcPort = srcPort return b } func (b *builder) WithDestAddr(destAddr string) *builder { b.msg.Header.DestAddr = destAddr return b } func (b *builder) WithDestPort(destPort uint64) *builder { b.msg.Header.DestPort = destPort return b } func (b *builder) WithHeaderItem(key, value string) *builder { // 保证map只初始化一次 b.once.Do(func() { b.msg.Header.Items = make(map[string]string) }) b.msg.Header.Items[key] = value return b } func (b *builder) WithBodyItem(record string) *builder { b.msg.Body.Items = append(b.msg.Body.Items, record) return b } // 创建Message对象，在最后一步调用 func (b *builder) Build() *Message { return b.msg } 复制代码 测试代码如下： package test ... func TestMessageBuilder(t *testing.T) { // 使用消息建造者进行对象创建 message := msg.Builder(). WithSrcAddr(&quot;192.168.0.1&quot;). WithSrcPort(1234). WithDestAddr(&quot;192.168.0.2&quot;). WithDestPort(8080). WithHeaderItem(&quot;contents&quot;, &quot;application/json&quot;). WithBodyItem(&quot;record1&quot;). WithBodyItem(&quot;record2&quot;). Build() if message.Header.SrcAddr != &quot;192.168.0.1&quot; { t.Errorf(&quot;expect src address 192.168.0.1, but actual %s.&quot;, message.Header.SrcAddr) } if message.Body.Items[0] != &quot;record1&quot; { t.Errorf(&quot;expect body item0 record1, but actual %s.&quot;, message.Body.Items[0]) } } // 运行结果 === RUN TestMessageBuilder --- PASS: TestMessageBuilder (0.00s) PASS 复制代码 从测试代码可知，使用建造者模式来进行对象创建，使用者不再需要知道对象具体的实现细节，代码可读性也更好。 工厂方法模式（Factory Method Pattern） 简述 工厂方法模式跟上一节讨论的建造者模式类似，都是将对象创建的逻辑封装起来，为使用者提供一个简单易用的对象创建接口。两者在应用场景上稍有区别，建造者模式更常用于需要传递多个参数来进行实例化的场景。 使用工厂方法来创建对象主要有两个好处： 1、代码可读性更好。相比于使用C++/Java中的构造函数，或者Go中的{}来创建对象，工厂方法因为可以通过函数名来表达代码含义，从而具备更好的可读性。比如，使用工厂方法productA := CreateProductA()创建一个ProductA对象，比直接使用productA := ProductA{}的可读性要好。 2、与使用者代码解耦。很多情况下，对象的创建往往是一个容易变化的点，通过工厂方法来封装对象的创建过程，可以在创建逻辑变更时，避免霰弹式修改。 工厂方法模式也有两种实现方式：（1）提供一个工厂对象，通过调用工厂对象的工厂方法来创建产品对象；（2）将工厂方法集成到产品对象中（C++/Java中对象的static方法，Go中同一package下的函数） Go实现 考虑有一个事件对象Event，分别有两种有效的时间类型Start和End： package event ... type Type uint8 // 事件类型定义 const ( Start Type = iota End ) // 事件抽象接口 type Event interface { EventType() Type Content() string } // 开始事件，实现了Event接口 type StartEvent struct{ content string } ... // 结束事件，实现了Event接口 type EndEvent struct{ content string } ... 复制代码 1、按照第一种实现方式，为Event提供一个工厂对象，具体代码如下： package event ... // 事件工厂对象 type Factory struct{} // 更具事件类型创建具体事件 func (e *Factory) Create(etype Type) Event { switch etype { case Start: return &amp;StartEvent{ content: &quot;this is start event&quot;, } case End: return &amp;EndEvent{ content: &quot;this is end event&quot;, } default: return nil } } 复制代码 测试代码如下： package test ... func TestEventFactory(t *testing.T) { factory := event.Factory{} e := factory.Create(event.Start) if e.EventType() != event.Start { t.Errorf(&quot;expect event.Start, but actual %v.&quot;, e.EventType()) } e = factory.Create(event.End) if e.EventType() != event.End { t.Errorf(&quot;expect event.End, but actual %v.&quot;, e.EventType()) } } // 运行结果 === RUN TestEventFactory --- PASS: TestEventFactory (0.00s) PASS 复制代码 2、按照第二种实现方式，分别给Start和End类型的Event单独提供一个工厂方法，代码如下： package event ... // Start类型Event的工厂方法 func OfStart() Event { return &amp;StartEvent{ content: &quot;this is start event&quot;, } } // End类型Event的工厂方法 func OfEnd() Event { return &amp;EndEvent{ content: &quot;this is end event&quot;, } } 复制代码 测试代码如下： package event ... func TestEvent(t *testing.T) { e := event.OfStart() if e.EventType() != event.Start { t.Errorf(&quot;expect event.Start, but actual %v.&quot;, e.EventType()) } e = event.OfEnd() if e.EventType() != event.End { t.Errorf(&quot;expect event.End, but actual %v.&quot;, e.EventType()) } } // 运行结果 === RUN TestEvent --- PASS: TestEvent (0.00s) PASS 复制代码 抽象工厂模式（Abstract Factory Pattern） 简述 在工厂方法模式中，我们通过一个工厂对象来创建一个产品族，具体创建哪个产品，则通过swtich-case的方式去判断。这也意味着该产品组上，每新增一类产品对象，都必须修改原来工厂对象的代码；而且随着产品的不断增多，工厂对象的职责也越来越重，违反了单一职责原则。 抽象工厂模式通过给工厂类新增一个抽象层解决了该问题，如上图所示，FactoryA和FactoryB都实现·抽象工厂接口，分别用于创建ProductA和ProductB。如果后续新增了ProductC，只需新增一个FactoryC即可，无需修改原有的代码；因为每个工厂只负责创建一个产品，因此也遵循了单一职责原则。 Go实现 考虑需要如下一个插件架构风格的消息处理系统，pipeline是消息处理的管道，其中包含了input、filter和output三个插件。我们需要实现根据配置来创建pipeline ，加载插件过程的实现非常适合使用工厂模式，其中input、filter和output三类插件的创建使用抽象工厂模式，而pipeline的创建则使用工厂方法模式。 各类插件和pipeline的接口定义如下： package plugin ... // 插件抽象接口定义 type Plugin interface {} // 输入插件，用于接收消息 type Input interface { Plugin Receive() string } // 过滤插件，用于处理消息 type Filter interface { Plugin Process(msg string) string } // 输出插件，用于发送消息 type Output interface { Plugin Send(msg string) } 复制代码 package pipeline ... // 消息管道的定义 type Pipeline struct { input plugin.Input filter plugin.Filter output plugin.Output } // 一个消息的处理流程为 input -&gt; filter -&gt; output func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } 复制代码 接着，我们定义input、filter、output三类插件接口的具体实现： package plugin ... // input插件名称与类型的映射关系，主要用于通过反射创建input对象 var inputNames = make(map[string]reflect.Type) // Hello input插件，接收“Hello World”消息 type HelloInput struct {} func (h *HelloInput) Receive() string { return &quot;Hello World&quot; } // 初始化input插件映射关系表 func init() { inputNames[&quot;hello&quot;] = reflect.TypeOf(HelloInput{}) } 复制代码 package plugin ... // filter插件名称与类型的映射关系，主要用于通过反射创建filter对象 var filterNames = make(map[string]reflect.Type) // Upper filter插件，将消息全部字母转成大写 type UpperFilter struct {} func (u *UpperFilter) Process(msg string) string { return strings.ToUpper(msg) } // 初始化filter插件映射关系表 func init() { filterNames[&quot;upper&quot;] = reflect.TypeOf(UpperFilter{}) } 复制代码 package plugin ... // output插件名称与类型的映射关系，主要用于通过反射创建output对象 var outputNames = make(map[string]reflect.Type) // Console output插件，将消息输出到控制台上 type ConsoleOutput struct {} func (c *ConsoleOutput) Send(msg string) { fmt.Println(msg) } // 初始化output插件映射关系表 func init() { outputNames[&quot;console&quot;] = reflect.TypeOf(ConsoleOutput{}) } 复制代码 然后，我们定义插件抽象工厂接口，以及对应插件的工厂实现： package plugin ... // 插件抽象工厂接口 type Factory interface { Create(conf Config) Plugin } // input插件工厂对象，实现Factory接口 type InputFactory struct{} // 读取配置，通过反射机制进行对象实例化 func (i *InputFactory) Create(conf Config) Plugin { t, _ := inputNames[conf.Name] return reflect.New(t).Interface().(Plugin) } // filter和output插件工厂实现类似 type FilterFactory struct{} func (f *FilterFactory) Create(conf Config) Plugin { t, _ := filterNames[conf.Name] return reflect.New(t).Interface().(Plugin) } type OutputFactory struct{} func (o *OutputFactory) Create(conf Config) Plugin { t, _ := outputNames[conf.Name] return reflect.New(t).Interface().(Plugin) } 复制代码 最后定义pipeline的工厂方法，调用plugin.Factory抽象工厂完成pipelien对象的实例化： package pipeline ... // 保存用于创建Plugin的工厂实例，其中map的key为插件类型，value为抽象工厂接口 var pluginFactories = make(map[plugin.Type]plugin.Factory) // 根据plugin.Type返回对应Plugin类型的工厂实例 func factoryOf(t plugin.Type) plugin.Factory { factory, _ := pluginFactories[t] return factory } // pipeline工厂方法，根据配置创建一个Pipeline实例 func Of(conf Config) *Pipeline { p := &amp;Pipeline{} p.input = factoryOf(plugin.InputType).Create(conf.Input).(plugin.Input) p.filter = factoryOf(plugin.FilterType).Create(conf.Filter).(plugin.Filter) p.output = factoryOf(plugin.OutputType).Create(conf.Output).(plugin.Output) return p } // 初始化插件工厂对象 func init() { pluginFactories[plugin.InputType] = &amp;plugin.InputFactory{} pluginFactories[plugin.FilterType] = &amp;plugin.FilterFactory{} pluginFactories[plugin.OutputType] = &amp;plugin.OutputFactory{} } 复制代码 测试代码如下： package test ... func TestPipeline(t *testing.T) { // 其中pipeline.DefaultConfig()的配置内容见【抽象工厂模式示例图】 // 消息处理流程为 HelloInput -&gt; UpperFilter -&gt; ConsoleOutput p := pipeline.Of(pipeline.DefaultConfig()) p.Exec() } // 运行结果 === RUN TestPipeline HELLO WORLD --- PASS: TestPipeline (0.00s) PASS 复制代码 原型模式（Prototype Pattern） 简述 原型模式主要解决对象复制的问题，它的核心就是clone()方法，返回Prototype对象的复制品。在程序设计过程中，往往会遇到有一些场景需要大量相同的对象，如果不使用原型模式，那么我们可能会这样进行对象的创建：新创建一个相同对象的实例，然后遍历原始对象的所有成员变量， 并将成员变量值复制到新对象中。这种方法的缺点很明显，那就是使用者必须知道对象的实现细节，导致代码之间的耦合。另外，对象很有可能存在除了对象本身以外不可见的变量，这种情况下该方法就行不通了。 对于这种情况，更好的方法就是使用原型模式，将复制逻辑委托给对象本身，这样，上述两个问题也都迎刃而解了。 Go实现 还是以建造者模式一节中的Message作为例子，现在设计一个Prototype抽象接口： package prototype ... // 原型复制抽象接口 type Prototype interface { clone() Prototype } type Message struct { Header *Header Body *Body } func (m *Message) clone() Prototype { msg := *m return &amp;msg } 复制代码 测试代码如下： package test ... func TestPrototype(t *testing.T) { message := msg.Builder(). WithSrcAddr(&quot;192.168.0.1&quot;). WithSrcPort(1234). WithDestAddr(&quot;192.168.0.2&quot;). WithDestPort(8080). WithHeaderItem(&quot;contents&quot;, &quot;application/json&quot;). WithBodyItem(&quot;record1&quot;). WithBodyItem(&quot;record2&quot;). Build() // 复制一份消息 newMessage := message.Clone().(*msg.Message) if newMessage.Header.SrcAddr != message.Header.SrcAddr { t.Errorf(&quot;Clone Message failed.&quot;) } if newMessage.Body.Items[0] != message.Body.Items[0] { t.Errorf(&quot;Clone Message failed.&quot;) } } // 运行结果 === RUN TestPrototype --- PASS: TestPrototype (0.00s) PASS 复制代码 总结 本文主要介绍了GoF的23种设计模式中的5种创建型模式，创建型模式的目的都是提供一个简单的接口，让对象的创建过程与使用者解耦。其中，单例模式主要用于保证一个类仅有一个实例，并提供一个访问它的全局访问点；建造者模式主要解决需要创建对象时需要传入多个参数，或者对初始化顺序有要求的场景；工厂方法模式通过提供一个工厂对象或者工厂方法，为使用者隐藏了对象创建的细节；抽象工厂模式是对工厂方法模式的优化，通过为工厂对象新增一个抽象层，让工厂对象遵循单一职责原则，也避免了霰弹式修改；原型模式则让对象复制更加简单。 下一篇文章，将介绍23种设计模式中的7种结构型模式（Structural Pattern），及其Go语言的实现。 ","link":"https://ChicRingo.github.io/post/shi-yong-go-shi-xian-gof-de-23-chong-she-ji-mo-shi-yi/"},{"title":"用 golang 实现的十大经典排序","content":"用go语言实现的十大经典排序 冒泡排序 // 冒泡排序 func bubble(nums []int) []int { numLen := len(nums) for i := 0; i &lt; numLen; i++ { // 按相邻两个一起比较，所以最后一个不用遍历 -1,已经排序的也不用重新排序，所以-i，不写也可 for j := 0; j &lt; numLen-1-i; j++ { // 当前值大于后一个值，则对换位置 if nums[j] &gt; nums[j+1] { nums[j], nums[j+1] = nums[j+1], nums[j] } } } return nums } 选择排序 func selection(nums []int) []int { numLen := len(nums) //最后一个不用排序了 for i := 0; i &lt; numLen-1; i++ { //每次最小值的位置index var minIndex = i // 从第二个开始排序，也就是i+1 for j := i + 1; j &lt; numLen; j++ { if nums[j] &lt; nums[minIndex] { minIndex = j } } nums[i], nums[minIndex] = nums[minIndex], nums[i] } return nums } 插入排序 func insertion(nums []int) []int { // 网上写法 for i, tmp := range nums { // 前一个索引值 preIndex := i - 1 // 定义一个临时变量取当前的值（挖出来腾地方，给前面的往后挪位置的空间 //tmp := nums[i] // 如果当前值 tmp 小于前面的值，就把前面的值往后挪，因为tmp已经保存过相当于空的 for preIndex &gt;= 0 &amp;&amp; tmp &lt; nums[preIndex] { nums[preIndex+1] = nums[preIndex] preIndex-- } // 不满足以上条件时，说明没有比tmp更小的，就保存tmp当前值到新的位置 nums[preIndex+1] = tmp } // 自己写法 //numLen := len(nums) //for i := 1; i &lt; numLen; i++ { //从第2个开始，i=1开始 // // temp := nums[i] // 定义一个临时变量取当前的值 // // 把该值tmp与之前的数 从后往前进行比较 // for j := i - 1; j &gt;= 0; j-- { // // 当 当前值tmp 比之前的某个值大,那么插入,否则把每个值往后移一位 // if temp &gt; nums[j] { // nums[j+1] = temp // break // } else { // nums[j+1] = nums[j] // } // // 如果都移动了,然后遍历到0了,说明当前值是最小的,把当前值放到最小的位置 // if j == 0 { // nums[0] = temp // } // } //} return nums } 希尔排序 归并排序 快速排序 func partition(nums []int, left, right int) int { // 设基准值 privot 为left privot := left index := privot + 1 for i := index; i &lt;= right; i++ { if nums[i] &lt; nums[privot] { nums[i], nums[index] = nums[index], nums[i] index++ } } nums[privot], nums[index-1] = nums[index-1], nums[privot] return index - 1 } func quickSort(nums []int, left, right int) { // 如果数组长度小于等于1，说明这个数组分区不需要再排序了，直接return if len(nums) &lt;= 1 { return } // 如果左小于右， if left &lt; right { partIndex := partition(nums, left, right) quickSort(nums, left, partIndex-1) quickSort(nums, partIndex+1, right) } return } 堆排序 ","link":"https://ChicRingo.github.io/post/yong-golang-shi-xian-de-shi-da-jing-dian-pai-xu/"},{"title":"我擦~字符串转字节切片后，切片的容量竟然千奇百怪","content":"字符串转字节切片步骤如下 判断是否是常量， 如果是常量则转换为等容量等长的字节切片 如果是变量， 先判断生成的切片是否发生变量逃逸 如果逃逸或者字符串长度&gt;32， 则根据字符串长度可以计算出不同的容量 如果未逃逸且字符串长度&lt;=32, 则字符切片容量为32 以下文章来源于新世界杂货铺 ，作者许文 新世界杂货铺作为一名Gopher， 我愿称之为Go的干(杂)货铺子！ 神奇的现象 切片， 切片， 又是切片! 今天遇到的神奇问题和切片有关， 具体怎么个神奇法， 我们来看看下面几个现象 现象一 a := &quot;abc&quot; bs := []byte(a) fmt.Println(bs, len(bs), cap(bs)) // 输出： [97 98 99] 3 8 现象二 a := &quot;abc&quot; bs := []byte(a) fmt.Println(len(bs), cap(bs)) // 输出: 3 32 现象三 bs := []byte(&quot;abc&quot;) fmt.Println(len(bs), cap(bs)) // 输出: 3 3 现象四 a := &quot;&quot; bs := []byte(a) fmt.Println(bs, len(bs), cap(bs)) // 输出: [] 0 0 现象五 a := &quot;&quot; bs := []byte(a) fmt.Println(len(bs), cap(bs)) // 输出: 0 32 分析 到这儿我已经满脑子问号了 字符串变量转切片 一个小小的字符串转切片， 内部究竟发生了什么， 竟然如此的神奇。这种时候只好祭出汇编大法， 看看汇编代码(希望之后有机会能够对go的汇编语法进行简单的介绍)有没有什么关键词能够帮助我们 以下为现象一转换的汇编代码关键部分 &quot;&quot;.main STEXT size=495 args=0x0 locals=0xd8 0x0000 00000 (test.go:5) TEXT &quot;&quot;.main(SB), ABIInternal, $216-0 0x0000 00000 (test.go:5) MOVQ (TLS), CX 0x0009 00009 (test.go:5) LEAQ -88(SP), AX 0x000e 00014 (test.go:5) CMPQ AX, 16(CX) 0x0012 00018 (test.go:5) JLS 485 0x0018 00024 (test.go:5) SUBQ $216, SP 0x001f 00031 (test.go:5) MOVQ BP, 208(SP) 0x0027 00039 (test.go:5) LEAQ 208(SP), BP 0x002f 00047 (test.go:5) FUNCDATA $0, gclocals·7be4bbacbfdb05fb3044e36c22b41e8b(SB) 0x002f 00047 (test.go:5) FUNCDATA $1, gclocals·648d0b72bb9d7f59fbfdbee57a078eee(SB) 0x002f 00047 (test.go:5) FUNCDATA $2, gclocals·2dfddcc7190380b1ae77e69d81f0a101(SB) 0x002f 00047 (test.go:5) FUNCDATA $3, &quot;&quot;.main.stkobj(SB) 0x002f 00047 (test.go:6) PCDATA $0, $1 0x002f 00047 (test.go:6) PCDATA $1, $0 0x002f 00047 (test.go:6) LEAQ go.string.&quot;abc&quot;(SB), AX 0x0036 00054 (test.go:6) MOVQ AX, &quot;&quot;.a+96(SP) 0x003b 00059 (test.go:6) MOVQ $3, &quot;&quot;.a+104(SP) 0x0044 00068 (test.go:7) MOVQ $0, (SP) 0x004c 00076 (test.go:7) PCDATA $0, $0 0x004c 00076 (test.go:7) MOVQ AX, 8(SP) 0x0051 00081 (test.go:7) MOVQ $3, 16(SP) 0x005a 00090 (test.go:7) CALL runtime.stringtoslicebyte(SB) 0x005f 00095 (test.go:7) MOVQ 40(SP), AX 0x0064 00100 (test.go:7) MOVQ 32(SP), CX 0x0069 00105 (test.go:7) PCDATA $0, $2 0x0069 00105 (test.go:7) MOVQ 24(SP), DX 0x006e 00110 (test.go:7) PCDATA $0, $0 0x006e 00110 (test.go:7) PCDATA $1, $1 0x006e 00110 (test.go:7) MOVQ DX, &quot;&quot;.bs+112(SP) 0x0073 00115 (test.go:7) MOVQ CX, &quot;&quot;.bs+120(SP) 0x0078 00120 (test.go:7) MOVQ AX, &quot;&quot;.bs+128(SP) 以下为现象二转换的汇编代码关键部分 &quot;&quot;.main STEXT size=393 args=0x0 locals=0xe0 0x0000 00000 (test.go:5) TEXT &quot;&quot;.main(SB), ABIInternal, $224-0 0x0000 00000 (test.go:5) MOVQ (TLS), CX 0x0009 00009 (test.go:5) LEAQ -96(SP), AX 0x000e 00014 (test.go:5) CMPQ AX, 16(CX) 0x0012 00018 (test.go:5) JLS 383 0x0018 00024 (test.go:5) SUBQ $224, SP 0x001f 00031 (test.go:5) MOVQ BP, 216(SP) 0x0027 00039 (test.go:5) LEAQ 216(SP), BP 0x002f 00047 (test.go:5) FUNCDATA $0, gclocals·0ce64bbc7cfa5ef04d41c861de81a3d7(SB) 0x002f 00047 (test.go:5) FUNCDATA $1, gclocals·00590b99cfcd6d71bbbc6e05cb4f8bf8(SB) 0x002f 00047 (test.go:5) FUNCDATA $2, gclocals·8dcadbff7c52509cfe2d26e4d7d24689(SB) 0x002f 00047 (test.go:5) FUNCDATA $3, &quot;&quot;.main.stkobj(SB) 0x002f 00047 (test.go:6) PCDATA $0, $1 0x002f 00047 (test.go:6) PCDATA $1, $0 0x002f 00047 (test.go:6) LEAQ go.string.&quot;abc&quot;(SB), AX 0x0036 00054 (test.go:6) MOVQ AX, &quot;&quot;.a+120(SP) 0x003b 00059 (test.go:6) MOVQ $3, &quot;&quot;.a+128(SP) 0x0047 00071 (test.go:7) PCDATA $0, $2 0x0047 00071 (test.go:7) LEAQ &quot;&quot;..autotmp_5+64(SP), CX 0x004c 00076 (test.go:7) PCDATA $0, $1 0x004c 00076 (test.go:7) MOVQ CX, (SP) 0x0050 00080 (test.go:7) PCDATA $0, $0 0x0050 00080 (test.go:7) MOVQ AX, 8(SP) 0x0055 00085 (test.go:7) MOVQ $3, 16(SP) 0x005e 00094 (test.go:7) CALL runtime.stringtoslicebyte(SB) 0x0063 00099 (test.go:7) MOVQ 40(SP), AX 0x0068 00104 (test.go:7) MOVQ 32(SP), CX 0x006d 00109 (test.go:7) PCDATA $0, $3 0x006d 00109 (test.go:7) MOVQ 24(SP), DX 0x0072 00114 (test.go:7) PCDATA $0, $0 0x0072 00114 (test.go:7) PCDATA $1, $1 0x0072 00114 (test.go:7) MOVQ DX, &quot;&quot;.bs+136(SP) 0x007a 00122 (test.go:7) MOVQ CX, &quot;&quot;.bs+144(SP) 0x0082 00130 (test.go:7) MOVQ AX, &quot;&quot;.bs+152(SP) 在看汇编代码之前， 我们首先来看一看runtime.stringtoslicebyte的函数签名 func stringtoslicebyte(buf *tmpBuf, s string) []byte 到这里只靠关键词已经无法看出更多的信息了,还是需要稍微了解一下汇编的语法,笔者在这里列出一点简单的分析， 之后我们还是可以通过取巧的方法发现更多的东西 // 现象一给runtime.stringtoslicebyte的传参 0x002f 00047 (test.go:6) LEAQ go.string.&quot;abc&quot;(SB), AX // 将字符串&quot;abc&quot;放入寄存器AX 0x0036 00054 (test.go:6) MOVQ AX, &quot;&quot;.a+96(SP) // 将AX中的内容存入变量a中 0x003b 00059 (test.go:6) MOVQ $3, &quot;&quot;.a+104(SP) // 将字符串长度3存入变量a中 0x0044 00068 (test.go:7) MOVQ $0, (SP) // 将0 传递个runtime.stringtoslicebyte(SB)的第一个参数(笔者猜测对应go中的nil) 0x004c 00076 (test.go:7) PCDATA $0, $0 // 据说和gc有关， 具体还不清楚， 一般情况可以忽略 0x004c 00076 (test.go:7) MOVQ AX, 8(SP) // 将AX中的内容传递给runtime.stringtoslicebyte(SB)的第二个参数 0x0051 00081 (test.go:7) MOVQ $3, 16(SP) // 将字符串长度传递给runtime.stringtoslicebyte(SB)的第二个参数 0x005a 00090 (test.go:7) CALL runtime.stringtoslicebyte(SB) // 调用函数， 此行后面的几行代码是将返回值赋值给变量bs // 现象二给runtime.stringtoslicebyte的传参 0x002f 00047 (test.go:6) LEAQ go.string.&quot;abc&quot;(SB), AX // 将字符串&quot;abc&quot;放入寄存器AX 0x0036 00054 (test.go:6) MOVQ AX, &quot;&quot;.a+120(SP) // 将AX中的内容存入变量a中 0x003b 00059 (test.go:6) MOVQ $3, &quot;&quot;.a+128(SP) // 将字符串长度3存入变量a中 0x0047 00071 (test.go:7) PCDATA $0, $2 0x0047 00071 (test.go:7) LEAQ &quot;&quot;..autotmp_5+64(SP), CX // 将内部变量autotmp_5放入寄存器CX 0x004c 00076 (test.go:7) PCDATA $0, $1 0x004c 00076 (test.go:7) MOVQ CX, (SP) // 将CX中的内容传递给runtime.stringtoslicebyte(SB)的第一个参数 0x0050 00080 (test.go:7) PCDATA $0, $0 0x0050 00080 (test.go:7) MOVQ AX, 8(SP) // 将AX中的内容传递给runtime.stringtoslicebyte(SB)的第二个参数 0x0055 00085 (test.go:7) MOVQ $3, 16(SP) // 将字符串长度传递给runtime.stringtoslicebyte(SB)的第二个参数 0x005e 00094 (test.go:7) CALL runtime.stringtoslicebyte(SB) 通过上面汇编代码的分析可以知道，现象一和现象二的区别就是传递给runtime.stringtoslicebyte的第一个参数不同。通过对runtime包中stringtoslicebyte函数分析，第一个参数是否有值和字符串长度会影响代码执行的分支，从而生成不同的切片， 因此容量不一样也是常理之中， 下面我们看源码 func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte if buf != nil &amp;&amp; len(s) &lt;= len(buf) { *buf = tmpBuf{} b = buf[:len(s)] } else { b = rawbyteslice(len(s)) } copy(b, s) return b } 然而， stringtoslicebyte的第一个参数什么情况下才会有值，什么情况下为nil, 我们仍然不清楚。那怎么办呢， 只好祭出全局搜索大法： # 在go源码根目录执行下面的命令 grep stringtoslicebyte -r . | grep -v &quot;//&quot; 最终在go的编译器源码cmd/compile/internal/gc/walk.go发现了如下代码块 我们查看mkcall 函数签名可以知道, 从第四个参数开始的所有变量都会作为参数传递给第一个参数对应的函数， 最后生成一个*Node的变量。其中Node结构体解释如下: // A Node is a single node in the syntax tree. // Actually the syntax tree is a syntax DAG, because there is only one // node with Op=ONAME for a given instance of a variable x. // The same is true for Op=OTYPE and Op=OLITERAL. See Node.mayBeShared. 综合上述信息我们得出的结论是，编译器会对stringtoslicebyte的函数调用生成一个AST(抽象语法树)对应的节点。因此我们也知道传递给stringtoslicebyte函数的第一个变量也就对应于上图中的变量a. 其中a的初始值为nodnil()的返回值，即默认为nil. 但是n.Esc == EscNone时，a会变成一个数组。我们看一下EscNone的解释. // 此代码位于cmd/compile/internal/gc/esc.go中 const ( // ... EscNone // Does not escape to heap, result, or parameters. ... ) 由上可知, EscNone用来判断变量是否逃逸,到这儿了我们就很好办了，接下来我们对现象一和现象二的代码进行逃逸分析. # 执行变量逃逸分析命令: go run -gcflags '-m -l' test.go # 现象一逃逸分析如下： ./test.go:7:14: ([]byte)(a) escapes to heap ./test.go:8:13: main ... argument does not escape ./test.go:8:13: bs escapes to heap ./test.go:8:21: len(bs) escapes to heap ./test.go:8:30: cap(bs) escapes to heap [97 98 99] 3 8 # 现象二逃逸分析如下： ./test.go:7:14: main ([]byte)(a) does not escape ./test.go:8:13: main ... argument does not escape ./test.go:8:17: len(bs) escapes to heap ./test.go:8:26: cap(bs) escapes to heap 3 32 根据上面的信息我们知道在现象一中，bs变量发生了逃逸，现象二中变量未发生逃逸，也就是说stringtoslicebyte函数的第一个参数在变量未发生逃逸时其值不为nil,变量发生逃逸时其值为nil。到这里我们已经搞明白stringtoslicebyte的第一个参数了， 那我们继续分析stringtoslicebyte的内部逻辑 我们在runtime/string.go中看到stringtoslicebyte第一个参数的类型定义如下： const tmpStringBufSize = 32 type tmpBuf [tmpStringBufSize]byte 综上: 现象二中bs变量未发生变量逃逸, stringtoslicebyte第一个参数不为空且是一个长度为32的byte数组, 因此在现象二中生成了一个容量为32的切片 根据对stringtoslicebyte的源码分析， 我们知道现象一调用了rawbyteslice函数 func rawbyteslice(size int) (b []byte) { cap := roundupsize(uintptr(size)) p := mallocgc(cap, nil, false) if cap != uintptr(size) { memclrNoHeapPointers(add(p, uintptr(size)), cap-uintptr(size)) } *(*slice)(unsafe.Pointer(&amp;b)) = slice{p, size, int(cap)} return } 由上面的代码知道， 切片的容量通过runtime/msize.go中的roundupsize函数计算得出, 其中_MaxSmallSize和class_to_size均定义在runtime/sizeclasses.go func roundupsize(size uintptr) uintptr { if size &lt; _MaxSmallSize { if size &lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { return uintptr(class_to_size[size_to_class128[(size-smallSizeMax+largeSizeDiv-1)/largeSizeDiv]]) } } if size+_PageSize &lt; size { return size } return round(size, _PageSize) } 由于字符串abc的长度小于_MaxSmallSize(32768)，故切片的长度只能取数组class_to_size中的值， 即0, 8, 16, 32, 48, 64, 80, 96, 112, 128....s 至此, 现象一中切片容量为什么为8也真相大白了。相信到这里很多人已经明白现象四和现象五是怎么回事儿了, 其逻辑分别与现象一和现象二是一致的， 有兴趣的， 可以在自己的电脑上面试一试。 字符串直接转切片 那你说了这么多， 现象三还是不能解释啊。请各位看官莫急， 接下来我们继续分析。 相信各位细心的小伙伴应该早就发现了我们在上面的cmd/compile/internal/gc/walk.go源码图中折叠了部分代码， 现在我们就将这块神秘的代码赤裸裸的展示出来 我们分析这块代码发现,go编译器在将字符串转字节切片生成AST时，总共分为三步。 先判断该变量是否是常量字符串,如果是常量字符串,则直接通过types.NewArray创建一个和字符串等长的数组 常量字符串生成的切片变量也要进行逃逸分析，并判断其大小是否大于函数栈允许分配给变量的最大长度， 从而判断节点是分配在栈上还是在堆上 最后，如果字符串长度是大于0， 将字符串内容复制到字节切片中， 然后返回。因此现象三中的切片容量是3也就完全清楚了 结论 字符串转字节切片步骤如下 判断是否是常量， 如果是常量则转换为等容量等长的字节切片 如果是变量， 先判断生成的切片是否发生变量逃逸 如果逃逸或者字符串长度&gt;32， 则根据字符串长度可以计算出不同的容量 如果未逃逸且字符串长度&lt;=32, 则字符切片容量为32 扩展 常见逃逸情况 函数返回局部指针 栈空间不足逃逸 动态类型逃逸, 很多函数参数为interface类型，比如fmt.Println(a ...interface{})，编译期间很难确定其参数的具体类型, 也会发生逃逸 闭包引用对象逃逸 注: 写本文时， 笔者所用go版本为: go1.13.4 生命不息， 探索不止， 后续将持续更新有关于go的技术探索 ","link":"https://ChicRingo.github.io/post/wo-ca-~zi-fu-chuan-zhuan-zi-jie-qie-pian-hou-qie-pian-de-rong-liang-jing-ran-qian-qi-bai-guai/"},{"title":"使用 Hugo 搭建博客","content":"https://www.diguage.com/post/building-blog-with-hugo/ ","link":"https://ChicRingo.github.io/post/shi-yong-hugo-da-jian-bo-ke/"},{"title":"使用2个goroutine轮流打印一个数组","content":"今天遇到群友的一到面试题，感觉在各种地方看到很多次这种类似的题目，比如两个goroutine轮流打印奇偶数，所以记录整理下来。 package main import ( &quot;fmt&quot; &quot;sync&quot; ) // 使用2个goroutine轮流打印一个数组 var wg sync.WaitGroup var ch = make(chan bool) var send = make(chan int) func main() { wg.Add(3) nums := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} l := len(nums) go Send(nums, l) // 发送 go printOdd(l) // 打印奇数 go printEven(l) // 打印偶数 wg.Wait() } // 发送数组元素 func Send(nums []int, l int) { defer wg.Done() for i := 0; i &lt; l; i++ { a := nums[i] send &lt;- a } } // 打印奇数 func printEven(l int) { defer wg.Done() for i := 0; i &lt; l; i++ { ch &lt;- true if i&amp;1 == 0 { a := &lt;-send fmt.Println(&quot;printEven:&quot;, a) } } } // 打印偶数 func printOdd(l int) { defer wg.Done() for i := 0; i &lt; l; i++ { &lt;-ch if i&amp;1 == 1 { a := &lt;-send fmt.Println(&quot;printOdd: &quot;, a) } } } ","link":"https://ChicRingo.github.io/post/shi-yong-2-ge-goroutine-lun-liu-da-yin-yi-ge-shu-zu/"},{"title":"Golang 并发控制的两种模式","content":"Golang 两种常用的并发控制，使用 channel 和 WaitGroup 两种模式 package main import ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot; ) func main() { fmt.Println(&quot;Hello, 世界&quot;) handle1() handle2() } func handle1() { // 通过无缓冲通道来实现多 goroutine 并发控制 // create channel to synchronize done := make(chan bool) // 无缓冲通道 defer close(done) go func() { time.Sleep(1 * time.Second) fmt.Println(&quot;one done&quot;) done &lt;- true }() go func() { time.Sleep(1 * time.Second) fmt.Println(&quot;two done&quot;) done &lt;- true }() // wait until both are done for c := 0; c &lt; 2; c++ { &lt;-done } fmt.Println(&quot;handle1 done&quot;) // 当主 goroutine 运行到 &lt;-done 接受 channel 的值的时候，如果该 channel 中没有数据，就会一直阻塞等待，直到有值。 } func handle2() { // 通过sync包中的WaitGroup 实现并发控制 var wg sync.WaitGroup wg.Add(1) go func() { time.Sleep(1 * time.Second) fmt.Println(&quot;1 done&quot;) wg.Done() }() wg.Add(1) go func() { time.Sleep(1 * time.Second) fmt.Println(&quot;2 done&quot;) wg.Done() }() wg.Wait() fmt.Println(&quot;handle2 done&quot;) // 在 sync 包中，提供了 WaitGroup ，它会等待它收集的所有 goroutine 任务全部完成，在主 goroutine 中 Add(delta int) 索要等待goroutine 的数量。在每一个 goroutine 完成后 Done() 表示这一个goroutine 已经完成，当所有的 goroutine 都完成后，在主 goroutine 中 WaitGroup 返回。 } ","link":"https://ChicRingo.github.io/post/golang-bing-fa-kong-zhi-de-liang-chong-mo-shi/"},{"title":"Golang并发模型：并发协程的优雅退出","content":"文章来源：Golang并发模型：并发协程的优雅退出 goroutine作为Golang并发的核心，我们不仅要关注它们的创建和管理，当然还要关注如何合理的退出这些协程，不（合理）退出不然可能会造成阻塞、panic、程序行为异常、数据结果不正确等问题。这篇文章介绍，如何合理的退出goroutine，减少软件bug。 goroutine在退出方面，不像线程和进程，不能通过某种手段强制关闭它们，只能等待goroutine主动退出。但也无需为退出、关闭goroutine而烦恼，下面就介绍3种优雅退出goroutine的方法，只要采用这种最佳实践去设计，基本上就可以确保goroutine退出上不会有问题，尽情享用。 1：使用for-range退出 for-range是使用频率很高的结构，常用它来遍历数据，range能够感知channel的关闭，当channel被发送数据的协程关闭时，range就会结束，接着退出for循环。 它在并发中的使用场景是：当协程只从1个channel读取数据，然后进行处理，处理后协程退出。下面这个示例程序，当in通道被关闭时，协程可自动退出。 go func(in &lt;-chan int) { // Using for-range to exit goroutine // range has the ability to detect the close/end of a channel for x := range in { fmt.Printf(&quot;Process %d\\n&quot;, x) } }(inCh) 2：使用,ok退出 for-select也是使用频率很高的结构，select提供了多路复用的能力，所以for-select可以让函数具有持续多路处理多个channel的能力。但select没有感知channel的关闭，这引出了2个问题： 继续在关闭的通道上读，会读到通道传输数据类型的零值，如果是指针类型，读到nil，继续处理还会产生nil。 继续在关闭的通道上写，将会panic。 问题2可以这样解决，通道只由发送方关闭，接收方不可关闭，即某个写通道只由使用该select的协程关闭，select中就不存在继续在关闭的通道上写数据的问题。 问题1可以使用,ok来检测通道的关闭，使用情况有2种。 第一种：如果某个通道关闭后，需要退出协程，直接return即可。示例代码中，该协程需要从in通道读数据，还需要定时打印已经处理的数量，有2件事要做，所有不能使用for-range，需要使用for-select，当in关闭时，ok=false，我们直接返回。 go func() { // in for-select using ok to exit goroutine for { select { case x, ok := &lt;-in: if !ok { return } fmt.Printf(&quot;Process %d\\n&quot;, x) processedCnt++ case &lt;-t.C: fmt.Printf(&quot;Working, processedCnt = %d\\n&quot;, processedCnt) } } }() 第二种：如果某个通道关闭了，不再处理该通道，而是继续处理其他case，退出是等待所有的可读通道关闭。我们需要使用select的一个特征：select不会在nil的通道上进行等待。这种情况，把只读通道设置为nil即可解决。 go func() { // in for-select using ok to exit goroutine for { select { case x, ok := &lt;-in1: if !ok { in1 = nil } // Process case y, ok := &lt;-in2: if !ok { in2 = nil } // Process case &lt;-t.C: fmt.Printf(&quot;Working, processedCnt = %d\\n&quot;, processedCnt) } // If both in channel are closed, goroutine exit if in1 == nil &amp;&amp; in2 == nil { return } } }() 3：使用退出通道退出 使用,ok来退出使用for-select协程，解决是当读入数据的通道关闭时，没数据读时程序的正常结束。想想下面这2种场景，,ok还能适用吗？ 接收的协程要退出了，如果它直接退出，不告知发送协程，发送协程将阻塞。 启动了一个工作协程处理数据，如何通知它退出？ 使用一个专门的通道，发送退出的信号，可以解决这类问题。以第2个场景为例，协程入参包含一个停止通道stopCh，当stopCh被关闭，case &lt;-stopCh会执行，直接返回即可。 当我启动了100个worker时，只要main()执行关闭stopCh，每一个worker都会都到信号，进而关闭。如果main()向stopCh发送100个数据，这种就低效了。 func worker(stopCh &lt;-chan struct{}) { go func() { defer fmt.Println(&quot;worker exit&quot;) // Using stop channel explicit exit for { select { case &lt;-stopCh: fmt.Println(&quot;Recv stop signal&quot;) return case &lt;-t.C: fmt.Println(&quot;Working .&quot;) } } }() return } 最佳实践回顾 发送协程主动关闭通道，接收协程不关闭通道。技巧：把接收方的通道入参声明为只读，如果接收协程关闭只读协程，编译时就会报错。 协程处理1个通道，并且是读时，协程优先使用for-range，因为range可以关闭通道的关闭自动退出协程。 ,ok可以处理多个读通道关闭，需要关闭当前使用for-select的协程。 显式关闭通道stopCh可以处理主动通知协程退出的场景。 完整示例代码 本文所有代码都在仓库，可查看完整示例代码：https://github.com/Shitaibin/golang_goroutine_exit 并发系列文章推荐 Golang并发模型：轻松入门流水线模型 Golang并发模型：轻松入门流水线FAN模式 Golang并发模型：并发协程的优雅退出 如果这篇文章对你有帮助，不妨关注下我的Github，有文章会收到通知。 本文作者：大彬 如果喜欢本文，随意转载，但请保留此原文链接：http://lessisbetter.site/2018/12/02/golang-exit-goroutine-in-3-ways/ ","link":"https://ChicRingo.github.io/post/golang-bing-fa-mo-xing-bing-fa-xie-cheng-de-you-ya-tui-chu/"},{"title":"用Golang写爬虫(一)","content":"使用 Golang 对豆瓣爬虫 原文地址: https://strconv.com/posts/web-crawler-exercise-1/ 之前一直都是再用Python写爬虫，最近想体验下Golang写爬虫的感觉，所以就有了这个系列。我想要抓取的页面是豆瓣Top250页面，选择它的理由有3个: 豆瓣页面代码相对规范 豆瓣对爬虫爱好者相对更宽容 Top250页面简洁，很适合拿来练手 我们先看第一版的代码。 按逻辑我把抓取代码分成2个部分： HTTP请求 解析页面中的内容 我们先看HTTP请求，Golang语言的HTTP请求库不需要使用第三方的库，标准库就内置了足够好的支持： import ( &quot;fmt&quot; &quot;net/http&quot; &quot;io/ioutil&quot; ) func fetch (url string) string { fmt.Println(&quot;Fetch Url&quot;, url) client := &amp;http.Client{} req, _ := http.NewRequest(&quot;GET&quot;, url, nil) req.Header.Set(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)&quot;) resp, err := client.Do(req) if err != nil { fmt.Println(&quot;Http get err:&quot;, err) return &quot;&quot; } if resp.StatusCode != 200 { fmt.Println(&quot;Http status code:&quot;, resp.StatusCode) return &quot;&quot; } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(&quot;Read error&quot;, err) return &quot;&quot; } return string(body) } 我把URL请求的逻辑都放在了fetch函数中，里面做了一些异常处理。值得说的有2点： 在Header中设置了User-Agent，让访问看起来更像搜索引擎Bot。如果一个网站希望自己的内容被Google收录那么他就不会拒绝这样的UA的访问。 需要通过ioutil.ReadAll 读取resp的body内容，最后用string(body)把它转化成字符串 接着就是解析页面的部分： import ( &quot;regexp&quot; &quot;strings&quot; ) func parseUrls(url string) { body := fetch(url) body = strings.Replace(body, &quot;\\n&quot;, &quot;&quot;, -1) rp := regexp.MustCompile(`&lt;div class=&quot;hd&quot;&gt;(.*?)&lt;/div&gt;`) titleRe := regexp.MustCompile(`&lt;span class=&quot;title&quot;&gt;(.*?)&lt;/span&gt;`) idRe := regexp.MustCompile(`&lt;a href=&quot;https://movie.douban.com/subject/(\\d+)/&quot;`) items := rp.FindAllStringSubmatch(body, -1) for _, item := range items { fmt.Println(idRe.FindStringSubmatch(item[1])[1], titleRe.FindStringSubmatch(item[1])[1]) } } 这篇文章我们主要体验用标准库完成页面的解析，也就是用正则表达式包regexp来完成。不过要注意需要用strings.Replace(body, &quot;\\n&quot;, &quot;&quot;, -1)这步把body内容中的回车符去掉，要不然下面的正则表达式.*就不符合了。FindAllStringSubmatch方法会把符合正则表达式的结果都解析出来（一个列表），而FindStringSubmatch是找第一个符合的结果。 Top250页面是要翻页的，最后在main函数里面实现抓取全部Top250页面。另外为了和之后的改进做对比，我们加上代码运行耗时的逻辑： import ( &quot;time&quot; &quot;strconv&quot; ) func main() { start := time.Now() for i := 0; i &lt; 10; i++ { parseUrls(&quot;https://movie.douban.com/top250?start=&quot; + strconv.Itoa(25 * i)) } elapsed := time.Since(start) fmt.Printf(&quot;Took %s&quot;, elapsed) } 在Golang中把数字转成字符串需要使用strconv.Itoa（嘿嘿，本博客域名就是这个模块），这样就可以根据start的参数的不通拼出正确的页面路径。用一个for循环完成翻页。 运行起来非常快： ❯ go run crawler/doubanCrawler1.go ... # 省略输出 Took 1.454627547s 通过终端输出可以看到我们拿到了对应电影条目的ID和电影标题！ 代码地址 完整代码可以在这个地址找到。 ","link":"https://ChicRingo.github.io/post/yong-golang-xie-pa-chong-yi/"},{"title":"在 Go 中恰到好处的内存对齐","content":"在Golang中对结构体成员进行内存对齐，以此保证内存的访问边界，并可以优化内存占用 原文地址：在 Go 中恰到好处的内存对齐 问题 type Part1 struct { a bool b int32 c int8 d int64 e byte } 在开始之前，希望你计算一下 Part1 共占用的大小是多少呢？ func main() { fmt.Printf(&quot;bool size: %d\\n&quot;, unsafe.Sizeof(bool(true))) fmt.Printf(&quot;int32 size: %d\\n&quot;, unsafe.Sizeof(int32(0))) fmt.Printf(&quot;int8 size: %d\\n&quot;, unsafe.Sizeof(int8(0))) fmt.Printf(&quot;int64 size: %d\\n&quot;, unsafe.Sizeof(int64(0))) fmt.Printf(&quot;byte size: %d\\n&quot;, unsafe.Sizeof(byte(0))) fmt.Printf(&quot;string size: %d\\n&quot;, unsafe.Sizeof(&quot;EDDYCJY&quot;)) } 输出结果： bool size: 1 int32 size: 4 int8 size: 1 int64 size: 8 byte size: 1 string size: 16 这么一算，Part1 这一个结构体的占用内存大小为 1+4+1+8+1 = 15 个字节。相信有的小伙伴是这么算的，看上去也没什么毛病 真实情况是怎么样的呢？我们实际调用看看，如下： type Part1 struct { a bool b int32 c int8 d int64 e byte } func main() { part1 := Part1{} fmt.Printf(&quot;part1 size: %d, align: %d\\n&quot;, unsafe.Sizeof(part1), unsafe.Alignof(part1)) } 输出结果： part1 size: 32, align: 8 最终输出为占用 32 个字节。这与前面所预期的结果完全不一样。这充分地说明了先前的计算方式是错误的。为什么呢？ 在这里要提到 “内存对齐” 这一概念，才能够用正确的姿势去计算，接下来我们详细的讲讲它是什么 内存对齐 有的小伙伴可能会认为内存读取，就是一个简单的字节数组摆放 上图表示一个坑一个萝卜的内存读取方式。但实际上 CPU 并不会以一个一个字节去读取和写入内存。相反 CPU 读取内存是一块一块读取的，块的大小可以为 2、4、6、8、16 字节等大小。块大小我们称其为内存访问粒度。如下图： 在样例中，假设访问粒度为 4。 CPU 是以每 4 个字节大小的访问粒度去读取和写入内存的。这才是正确的姿势 为什么要关心对齐 你正在编写的代码在性能（CPU、Memory）方面有一定的要求 你正在处理向量方面的指令 某些硬件平台（ARM）体系不支持未对齐的内存访问 另外作为一个工程师，你也很有必要学习这块知识点哦 😃 为什么要做对齐 平台（移植性）原因：不是所有的硬件平台都能够访问任意地址上的任意数据。例如：特定的硬件平台只允许在特定地址获取特定类型的数据，否则会导致异常情况 性能原因：若访问未对齐的内存，将会导致 CPU 进行两次内存访问，并且要花费额外的时钟周期来处理对齐及运算。而本身就对齐的内存仅需要一次访问就可以完成读取动作 在上图中，假设从 Index 1 开始读取，将会出现很崩溃的问题。因为它的内存访问边界是不对齐的。因此 CPU 会做一些额外的处理工作。如下： CPU 首次读取未对齐地址的第一个内存块，读取 0-3 字节。并移除不需要的字节 0 CPU 再次读取未对齐地址的第二个内存块，读取 4-7 字节。并移除不需要的字节 5、6、7 字节 合并 1-4 字节的数据 合并后放入寄存器 从上述流程可得出，不做 “内存对齐” 是一件有点 “麻烦” 的事。因为它会增加许多耗费时间的动作 而假设做了内存对齐，从 Index 0 开始读取 4 个字节，只需要读取一次，也不需要额外的运算。这显然高效很多，是标准的空间换时间做法 默认系数 在不同平台上的编译器都有自己默认的 “对齐系数”，可通过预编译命令 #pragma pack(n) 进行变更，n 就是代指 “对齐系数”。一般来讲，我们常用的平台的系数如下： 32 位：4 64 位：8 另外要注意，不同硬件平台占用的大小和对齐值都可能是不一样的。因此本文的值不是唯一的，调试的时候需按本机的实际情况考虑 成员对齐 func main() { fmt.Printf(&quot;bool align: %d\\n&quot;, unsafe.Alignof(bool(true))) fmt.Printf(&quot;int32 align: %d\\n&quot;, unsafe.Alignof(int32(0))) fmt.Printf(&quot;int8 align: %d\\n&quot;, unsafe.Alignof(int8(0))) fmt.Printf(&quot;int64 align: %d\\n&quot;, unsafe.Alignof(int64(0))) fmt.Printf(&quot;byte align: %d\\n&quot;, unsafe.Alignof(byte(0))) fmt.Printf(&quot;string align: %d\\n&quot;, unsafe.Alignof(&quot;EDDYCJY&quot;)) fmt.Printf(&quot;map align: %d\\n&quot;, unsafe.Alignof(map[string]string{})) } 输出结果： bool align: 1 int32 align: 4 int8 align: 1 int64 align: 8 byte align: 1 string align: 8 map align: 8 在 Go 中可以调用 unsafe.Alignof 来返回相应类型的对齐系数。通过观察输出结果，可得知基本都是 2^n，最大也不会超过 8。这是因为我手提（64 位）编译器默认对齐系数是 8，因此最大值不会超过这个数 整体对齐 在上小节中，提到了结构体中的成员变量要做字节对齐。那么想当然身为最终结果的结构体，也是需要做字节对齐的 对齐规则 结构体的成员变量，第一个成员变量的偏移量为 0。往后的每个成员变量的对齐值必须为编译器默认对齐长度（#pragma pack(n)）或当前成员变量类型的长度（unsafe.Sizeof），取最小值作为当前类型的对齐值。其偏移量必须为对齐值的整数倍 结构体本身，对齐值必须为编译器默认对齐长度（#pragma pack(n)）或结构体的所有成员变量类型中的最大长度，取最大数的最小整数倍作为对齐值 结合以上两点，可得知若编译器默认对齐长度（#pragma pack(n)）超过结构体内成员变量的类型最大长度时，默认对齐长度是没有任何意义的 分析流程 接下来我们一起分析一下，“它” 到底经历了些什么，影响了 “预期” 结果 成员变量 类型 偏移量 自身占用 a bool 0 1 字节对齐 无 1 3 b int32 4 4 c int8 8 1 字节对齐 无 9 7 d int64 16 8 e byte 24 1 字节对齐 无 25 7 总占用大小 - - 32 成员对齐 第一个成员 a 类型为 bool 大小/对齐值为 1 字节 初始地址，偏移量为 0。占用了第 1 位 第二个成员 b 类型为 int32 大小/对齐值为 4 字节 根据规则 1，其偏移量必须为 4 的整数倍。确定偏移量为 4，因此 2-4 位为 Padding。而当前数值从第 5 位开始填充，到第 8 位。如下：axxx|bbbb 第三个成员 c 类型为 int8 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 8。不需要额外对齐，填充 1 个字节到第 9 位。如下：axxx|bbbb|c… 第四个成员 d 类型为 int64 大小/对齐值为 8 字节 根据规则 1，其偏移量必须为 8 的整数倍。确定偏移量为 16，因此 9-16 位为 Padding。而当前数值从第 17 位开始写入，到第 24 位。如下：axxx|bbbb|cxxx|xxxx|dddd|dddd 第五个成员 e 类型为 byte 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 24。不需要额外对齐，填充 1 个字节到第 25 位。如下：axxx|bbbb|cxxx|xxxx|dddd|dddd|e… 整体对齐 在每个成员变量进行对齐后，根据规则 2，整个结构体本身也要进行字节对齐，因为可发现它可能并不是 2^n，不是偶数倍。显然不符合对齐的规则 根据规则 2，可得出对齐值为 8。现在的偏移量为 25，不是 8 的整倍数。因此确定偏移量为 32。对结构体进行对齐 结果 Part1 内存布局：axxx|bbbb|cxxx|xxxx|dddd|dddd|exxx|xxxx 小结 通过本节的分析，可得知先前的 “推算” 为什么错误？ 是因为实际内存管理并非 “一个萝卜一个坑” 的思想。而是一块一块。通过空间换时间（效率）的思想来完成这块读取、写入。另外也需要兼顾不同平台的内存操作情况 巧妙的结构体 在上一小节，可得知根据成员变量的类型不同，其结构体的内存会产生对齐等动作。那假设字段顺序不同，会不会有什么变化呢？我们一起来试试吧 😃 type Part1 struct { a bool b int32 c int8 d int64 e byte } type Part2 struct { e byte c int8 a bool b int32 d int64 } func main() { part1 := Part1{} part2 := Part2{} fmt.Printf(&quot;part1 size: %d, align: %d\\n&quot;, unsafe.Sizeof(part1), unsafe.Alignof(part1)) fmt.Printf(&quot;part2 size: %d, align: %d\\n&quot;, unsafe.Sizeof(part2), unsafe.Alignof(part2)) } 输出结果： part1 size: 32, align: 8 part2 size: 16, align: 8 通过结果可以惊喜的发现，只是 “简单” 对成员变量的字段顺序进行改变，就改变了结构体占用大小 接下来我们一起剖析一下 Part2，看看它的内部到底和上一位之间有什么区别，才导致了这样的结果？ 分析流程 成员变量 类型 偏移量 自身占用 e byte 0 1 c int8 1 1 a bool 2 1 字节对齐 无 3 1 b int32 4 4 d int64 8 8 总占用大小 - - 16 成员对齐 第一个成员 e 类型为 byte 大小/对齐值为 1 字节 初始地址，偏移量为 0。占用了第 1 位 第二个成员 c 类型为 int8 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 2。不需要额外对齐 第三个成员 a 类型为 bool 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 3。不需要额外对齐 第四个成员 b 类型为 int32 大小/对齐值为 4 字节 根据规则 1，其偏移量必须为 4 的整数倍。确定偏移量为 4，因此第 3 位为 Padding。而当前数值从第 4 位开始填充，到第 8 位。如下：ecax|bbbb 第五个成员 d 类型为 int64 大小/对齐值为 8 字节 根据规则 1，其偏移量必须为 8 的整数倍。当前偏移量为 8。不需要额外对齐，从 9-16 位填充 8 个字节。如下：ecax|bbbb|dddd|dddd 整体对齐 符合规则 2，不需要额外对齐 结果 Part2 内存布局：ecax|bbbb|dddd|dddd 总结 通过对比 Part1 和 Part2 的内存布局，你会发现两者有很大的不同。如下： Part1：axxx|bbbb|cxxx|xxxx|dddd|dddd|exxx|xxxx Part2：ecax|bbbb|dddd|dddd 仔细一看，Part1 存在许多 Padding。显然它占据了不少空间，那么 Padding 是怎么出现的呢？ 通过本文的介绍，可得知是由于不同类型导致需要进行字节对齐，以此保证内存的访问边界 那么也不难理解，为什么调整结构体内成员变量的字段顺序就能达到缩小结构体占用大小的疑问了，是因为巧妙地减少了 Padding 的存在。让它们更 “紧凑” 了。这一点对于加深 Go 的内存布局印象和大对象的优化非常有帮 当然了，没什么特殊问题，你可以不关注这一块。但你要知道这块知识点 😄 参考 Data structure alignment Data alignment ","link":"https://ChicRingo.github.io/post/zai-go-zhong-qia-dao-hao-chu-de-nei-cun-dui-qi/"},{"title":"Golang 中零值的坑","content":"对于int, string, bool来说，声明这三种基本类型的变量，Go会默认分配一个零值，零值分别为 0 , '' ,false，所以在GORM中通过tag定义字段的默认值后，这些有默认值的字段在使用这些零值作为参数时，GORM不会把这些字段的值插入数据库中，这个坑一定要切记。 默认值 可以通过 tag 定义字段的默认值，比如： type User struct { ID int64 Name string `gorm:&quot;default:'小王子'&quot;` Age int64 } 注意： 通过tag定义字段的默认值，在创建记录时候生成的 SQL 语句会排除没有值或值为 零值 的字段。 在将记录插入到数据库后，Gorm会从数据库加载那些字段的默认值。 举个例子： var user = User{Name: &quot;&quot;, Age: 99} db.Create(&amp;user) 上面代码实际执行的SQL语句是INSERT INTO users(&quot;age&quot;) values('99');，排除了零值字段Name，而在数据库中这一条数据会使用设置的默认值小王子作为Name字段的值。 **注意：**所有字段的零值, 比如0, &quot;&quot;,false或者其它零值，都不会保存到数据库内，但会使用他们的默认值。 如果你想避免这种情况，可以考虑使用指针或实现 Scanner/Valuer接口，比如： 使用指针方式实现零值存入数据库 // 使用指针 type User struct { ID int64 Name *string `gorm:&quot;default:'小王子'&quot;` Age int64 } user := User{Name: new(string), Age: 18))} db.Create(&amp;user) // 此时数据库中该条记录name字段的值就是'' 使用Scanner/Valuer接口方式实现零值存入数据库 // 使用 Scanner/Valuer type User struct { ID int64 Name sql.NullString `gorm:&quot;default:'小王子'&quot;` // sql.NullString 实现了Scanner/Valuer接口 Age int64 } user := User{Name: sql.NullString{&quot;&quot;, true}, Age:18} db.Create(&amp;user) // 此时数据库中该条记录name字段的值就是'' ","link":"https://ChicRingo.github.io/post/golang-zhong-ling-zhi-de-keng/"},{"title":"Golang 中 range 的坑","content":"避免踩坑指北，Golang 中容易在 for range 中踩到的坑 使用 range 迭代遍历数组 range 会复制对象，而不是不是直接在原对象上操作。 示例一： func main() { a := [3]int{1, 2, 3} for _, v := range a { // 复制一份a遍历[1, 2, 3] v += 100 // v是复制对象中的值，不会改变a数组元素的值 } fmt.Println(a) // 1 2 3 } 示例二： func main() { a := [3]int{1, 2, 3} for i, v := range a { // i,v从a复制的对象里提取出 if i == 0 { a[1], a[2] = 200, 300 fmt.Println(a) // 输出[1 200 300] } a[i] = v + 100 // v是复制对象里的元素[1, 2, 3] } fmt.Println(a) // 输出[101, 102, 103] } 结果： [1 200 300] [101 102 103] 使用 range 迭代遍历切片 range迭代遍历引用类型时，底层的数据不会被复制： func main() { a := []int{1, 2, 3} // 改成slice for i, v := range a { if i == 0 { a[1], a[2] = 200, 300 fmt.Println(a) // [1 200 300] } a[i] = v + 100 } fmt.Println(a) // 输出[101 300 400] } 结果： [1 200 300] [101 300 400] 因为切片的内部结构为struct slice{*point, len, cap}。 数据部分是一个指针，指向地址，复制对象的时候只是把指针的值复制了，而不是重新拷贝一块新的内存再把值放进去，所以修改的时候还是修改的原来的值。 ","link":"https://ChicRingo.github.io/post/golang-zhong-range-de-keng/"},{"title":"Go 为什么这么“快”","content":"本文主要介绍了 Go 程序为了实现极高的并发性能，其内部调度器的实现架构（G-P-M 模型），以及为了最大限度利用计算资源，Go 调度器是如何处理线程阻塞的场景 转自知乎：Go为什么这么“快” 怎么让我们的系统更快 随着信息技术的迅速发展，单台服务器处理能力越来越强，迫使编程模式由从前的串行模式升级到并发模型。 并发模型包含 IO 多路复用、多进程以及多线程，这几种模型都各有优劣，现代复杂的高并发架构大多是几种模型协同使用，不同场景应用不同模型，扬长避短，发挥服务器的最大性能。 而多线程，因为其轻量和易用，成为并发编程中使用频率最高的并发模型，包括后衍生的协程等其他子产品，也都基于它。 并发 ≠ 并行 并发 (concurrency) 和 并行 ( parallelism) 是不同的。 在单个 CPU 核上，线程通过时间片或者让出控制权来实现任务切换，达到 &quot;同时&quot; 运行多个任务的目的，这就是所谓的并发。但实际上任何时刻都只有一个任务被执行，其他任务通过某种算法来排队。 多核 CPU 可以让同一进程内的 &quot;多个线程&quot; 做到真正意义上的同时运行，这才是并行。 进程、线程、协程 进程：进程是系统进行资源分配的基本单位，有独立的内存空间。 线程：线程是 CPU 调度和分派的基本单位，线程依附于进程存在，每个线程会共享父进程的资源。 协程：**协程是一种用户态的轻量级线程，**协程的调度完全由用户控制，协程间切换只需要保存任务的上下文，没有内核的开销。 线程上下文切换 由于中断处理，多任务处理，用户态切换等原因会导致 CPU 从一个线程切换到另一个线程，切换过程需要保存当前进程的状态并恢复另一个进程的状态。 上下文切换的代价是高昂的，因为在核心上交换线程会花费很多时间。上下文切换的延迟取决于不同的因素，大概在在 50 到 100 纳秒之间。考虑到硬件平均在每个核心上每纳秒执行 12 条指令，那么一次上下文切换可能会花费 600 到 1200 条指令的延迟时间。实际上，上下文切换占用了大量程序执行指令的时间。 如果存在跨核上下文切换（Cross-Core Context Switch），可能会导致 CPU 缓存失效（CPU 从缓存访问数据的成本大约 3 到 40 个时钟周期，从主存访问数据的成本大约 100 到 300 个时钟周期），这种场景的切换成本会更加昂贵。 Golang 为并发而生 Golang 从 2009 年正式发布以来，依靠其极高运行速度和高效的开发效率，迅速占据市场份额。Golang 从语言级别支持并发，通过轻量级协程 Goroutine 来实现程序并发运行。 Goroutine 非常轻量，主要体现在以下两个方面： 上下文切换代价小： Goroutine 上下文切换只涉及到三个寄存器（PC / SP / DX）的值修改；而对比线程的上下文切换则需要涉及模式切换（从用户态切换到内核态）、以及 16 个寄存器、PC、SP…等寄存器的刷新； 内存占用少： 线程栈空间通常是 2M，Goroutine 栈空间最小 2K； Golang 程序中可以轻松支持10w 级别的 Goroutine 运行，而线程数量达到 1k 时，内存占用就已经达到 2G。 Go 调度器实现机制： Go 程序通过调度器来调度**Goroutine 在内核线程上执行，**但是 G Goroutine并不直接绑定 OS 线程 M - Machine运行，而是由 Goroutine Scheduler 中的 P - Processor （逻辑处理器）来作获取内核线程资源的『中介』。 Go 调度器模型我们通常叫做G-P-M 模型，他包括 4 个重要结构，分别是G、P、M、Sched： **G:Goroutine，**每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。 G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。 **P: Processor，**表示逻辑处理器，对 G 来说，P 相当于 CPU 核，G 只有绑定到 P 才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等。 P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 &gt;= P 的数量）。 P 的数量由用户设置的 GoMAXPROCS 决定，但是不论 GoMAXPROCS 设置为多大，P 的数量最大为 256。 **M: Machine，**OS 内核线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait 队列中获取。 **M 的数量是不定的，由 Go Runtime 调整，**为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。 M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。 **Sched：Go 调度器，**它维护有存储 M 和 G 的队列以及调度器的一些状态信息等。 调度器循环的机制大致是从各种队列、P 的本地队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 Goexit 做清理工作并回到 M，如此反复。 理解 M、P、G 三者的关系，可以通过经典的地鼠推车搬砖的模型来说明其三者关系： 地鼠(Gopher)的工作任务是：工地上有若干砖头，地鼠借助小车把砖头运送到火种上去烧制。M 就可以看作图中的地鼠，P 就是小车，G 就是小车里装的砖。 弄清楚了它们三者的关系，下面我们就开始重点聊地鼠是如何在搬运砖块的。 Processor（P）： 根据用户设置的 **GoMAXPROCS **值来创建一批小车(P)。 Goroutine(G)： 通过 Go 关键字就是用来创建一个 Goroutine，也就相当于制造一块砖(G)，然后将这块砖(G)放入当前这辆小车(P)中。 Machine (M)： 地鼠(M)不能通过外部创建出来，只能砖(G)太多了，地鼠(M)又太少了，实在忙不过来，刚好还有空闲的小车(P)没有使用，那就从别处再借些地鼠(M)过来直到把小车(P)用完为止。 这里有一个地鼠(M)不够用，从别处借地鼠(M)的过程，这个过程就是创建一个内核线程(M)。 **需要注意的是：**地鼠(M) 如果没有小车(P)是没办法运砖的，小车(P)的数量决定了能够干活的地鼠(M)数量，在 Go 程序里面对应的是活动线程数； 在 Go 程序里我们通过下面的图示来展示 G-P-M 模型： P 代表可以“并行”运行的逻辑处理器，每个 P 都被分配到一个系统线程 M，G 代表 Go 协程。 Go 调度器中有两个不同的运行队列：全局运行队列(GRQ)和本地运行队列(LRQ)。 每个 P 都有一个 LRQ，用于管理分配给在 P 的上下文中执行的 Goroutines，这些 Goroutine 轮流被和 P 绑定的 M 进行上下文切换。GRQ 适用于尚未分配给 P 的 Goroutines。 **从上图可以看出，G 的数量可以远远大于 M 的数量，换句话说，Go 程序可以利用少量的内核级线程来支撑大量 Goroutine 的并发。**多个 Goroutine 通过用户级别的上下文切换来共享内核线程 M 的计算资源，但对于操作系统来说并没有线程上下文切换产生的性能损耗。 为了更加充分利用线程的计算资源，Go 调度器采取了以下几种调度策略： 任务窃取（work-stealing） 我们知道，现实情况有的 Goroutine 运行的快，有的慢，那么势必肯定会带来的问题就是，忙的忙死，闲的闲死，Go 肯定不允许摸鱼的 P 存在，势必要充分利用好计算资源。 为了提高 Go 并行处理能力，调高整体处理效率，当每个 P 之间的 G 任务不均衡时，调度器允许从 GRQ，或者其他 P 的 LRQ 中获取 G 执行。 减少阻塞 如果正在执行的 Goroutine 阻塞了线程 M 怎么办？P 上 LRQ 中的 Goroutine 会获取不到调度么？ 在 Go 里面阻塞主要分为一下 4 种场景： 场景 1：由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine； 场景 2：由于网络请求和 IO 操作导致 Goroutine 阻塞，这种阻塞的情况下，我们的 G 和 M 又会怎么做呢？ Go 程序提供了**网络轮询器（NetPoller）**来处理网络请求和 IO 操作的问题，其后台通过 kqueue（MacOS），epoll（Linux）或 iocp（Windows）来实现 IO 多路复用。 通过使用 NetPoller 进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用时阻塞 M。这可以让 M 执行 P 的 LRQ 中其他的 Goroutines，而不需要创建新的 M。有助于减少操作系统上的调度负载。 **下图展示它的工作原理：**G1 正在 M 上执行，还有 3 个 Goroutine 在 LRQ 上等待执行。网络轮询器空闲着，什么都没干。 接下来，G1 想要进行网络系统调用，因此它被移动到网络轮询器并且处理异步网络系统调用。然后，M 可以从 LRQ 执行另外的 Goroutine。此时，G2 就被上下文切换到 M 上了。 最后，异步网络系统调用由网络轮询器完成，G1 被移回到 P 的 LRQ 中。一旦 G1 可以在 M 上进行上下文切换，它负责的 Go 相关代码就可以再次执行。这里的最大优势是，执行网络系统调用不需要额外的 M。网络轮询器使用系统线程，它时刻处理一个有效的事件循环。 这种调用方式看起来很复杂，值得庆幸的是，Go 语言将该“复杂性”隐藏在 Runtime 中：Go 开发者无需关注 socket 是否是 non-block 的，也无需亲自注册文件描述符的回调，只需在每个连接对应的 Goroutine 中以“block I/O”的方式对待 socket 处理即可，实现了 goroutine-per-connection 简单的网络编程模式（但是大量的 Goroutine 也会带来额外的问题，比如栈内存增加和调度器负担加重）。 用户层眼中看到的 Goroutine 中的“block socket”，实际上是通过 Go runtime 中的 netpoller 通过 Non-block socket + I/O 多路复用机制“模拟”出来的。Go 中的 net 库正是按照这方式实现的。 **场景 3：**当调用一些系统方法的时候，如果系统方法调用的时候发生阻塞，这种情况下，网络轮询器（NetPoller）无法使用，而进行系统调用的 Goroutine 将阻塞当前 M。 让我们来看看同步系统调用（如文件 I/O）会导致 M 阻塞的情况：G1 将进行同步系统调用以阻塞 M1。 调度器介入后：识别出 G1 已导致 M1 阻塞，此时，调度器将 M1 与 P 分离，同时也将 G1 带走。然后调度器引入新的 M2 来服务 P。此时，可以从 LRQ 中选择 G2 并在 M2 上进行上下文切换。 阻塞的系统调用完成后：G1 可以移回 LRQ 并再次由 P 执行。如果这种情况再次发生，M1 将被放在旁边以备将来重复使用**。** **场景 4：**如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了。 Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。 只要下次这个 Goroutine 进行函数调用，那么就会被强占，同时也会保护现场，然后重新放入 P 的本地队列里面等待下次执行。 小结 本文主要从 Go 调度器架构层面上介绍了 G-P-M 模型，通过该模型怎样实现少量内核线程支撑大量 Goroutine 的并发运行。以及通过 NetPoller、sysmon 等帮助 Go 程序减少线程阻塞，充分利用已有的计算资源，从而最大限度提高 Go 程序的运行效率。 参考文档： https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html https://segmentfault.com/a/1190000016038785 https://segmentfault.com/a/1190000016611742 https://segmentfault.com/a/1190000017333717 https://segmentfault.com/a/1190000015352983 https://segmentfault.com/a/1190000015464889 https://www.cnblogs.com/lxmhhy/p/6041001.html https://www.cnblogs.com/mokafamily/p/9975980.html https://studyGolang.com/articles/9211 https://www.zhihu.com/question/20862617 https://codeburst.io/why-Goroutines-are-not-lightweight-threads-7c460c1f155f https://blog.csdn.net/tiandyoin/article/details/76556702 https://www.jianshu.com/p/cc3c0fefee43 https://www.jianshu.com/p/a315224886d2 作者： joellwang，腾讯 CSIG 后台开发工程师 更多精彩，尽在 腾讯技术 ","link":"https://ChicRingo.github.io/post/go-wei-shi-me-zhe-me-kuai/"},{"title":"Golang 面试题总结","content":"总结的一些 Golang 面试中遇到的问题，更新中 go的goroutine为什么快 Goroutine 非常轻量，主要体现在以下两个方面： 上下文切换代价小： Goroutine 上下文切换只涉及到三个寄存器（PC / SP / DX）的值修改；而对比线程的上下文切换则需要涉及模式切换（从用户态切换到内核态）、以及 16 个寄存器、PC、SP…等寄存器的刷新； **内存占用少：**线程栈空间通常是 2M，Goroutine 栈空间最小 2K； Golang 程序中可以轻松支持10w 级别的 Goroutine 运行，而线程数量达到 1k 时，内存占用就已经达到 2G。 在 Go 程序里我们通过下面的图示来展示 G-P-M 模型： P 代表可以“并行”运行的逻辑处理器，每个 P 都被分配到一个系统线程 M，G 代表 Go 协程。 Go 调度器中有两个不同的运行队列：全局运行队列(GRQ)和本地运行队列(LRQ)。 每个 P 都有一个 LRQ，用于管理分配给在 P 的上下文中执行的 Goroutines，这些 Goroutine 轮流被和 P 绑定的 M 进行上下文切换。GRQ 适用于尚未分配给 P 的 Goroutines。 **从上图可以看出，G 的数量可以远远大于 M 的数量，换句话说，Go 程序可以利用少量的内核级线程来支撑大量 Goroutine 的并发。**多个 Goroutine 通过用户级别的上下文切换来共享内核线程 M 的计算资源，但对于操作系统来说并没有线程上下文切换产生的性能损耗。 Go 为什么这么“快” 红黑树的特点 每个节点非红即黑； 根节点总是黑色的； 每个叶子节点都是黑色的空节点（NIL节点）； 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）； 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。 红黑树的应用： TreeMap、TreeSet以及JAVA8的HashMap底层都用到了红黑树。 红黑树自平衡调整方法： 变色 变色仅仅指的是红黑树节点的变色。因为红黑树节点必须是【红】或者【黑】这两中颜色，所以变色只是将当前的节点颜色进行变化，以满足特性（2，3，4，5）。 旋转 左旋操作动画（更加容易理解和记忆）： /*************对红黑树节点x进行左旋操作 ******************/ /* 左旋示意图：对节点x进行左旋 * p p * / / * x y * / \\ / \\ * lx y -----&gt; x ry * / \\ / \\ * ly ry lx ly * 左旋做了三件事： * 1. 将y的左子节点赋给x的右子节点,并将x赋给y左子节点的父节点(y左子节点非空时) * 2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右) * 3. 将y的左子节点设为x，将x的父节点设为y */ 左旋操作动画 /*************对红黑树节点y进行右旋操作 ******************/ /* 右旋示意图：对节点y进行右旋 * p p * / / * y x * / \\ / \\ * x ry -----&gt; lx y * / \\ / \\ * lx rx rx ry * 右旋做了三件事： * 1. 将x的右子节点赋给y的左子节点,并将y赋给x右子节点的父节点(x右子节点非空时) * 2. 将y的父节点p(非空时)赋给x的父节点，同时更新p的子节点为x(左或右) * 3. 将x的右子节点设为y，将y的父节点设为x */ 延伸：为什么着色成红色，而不是黑色呢？为什么呢？ 红黑树节点的添加 红黑树的第 5 条特征规定，任一节点到它子树的每个叶子节点的路径中都包含同样数量的黑节点。也就是说当我们往红黑树中插入一个黑色节点时，会违背这条特征。 同时第 4 条特征规定红色节点的左右孩子一定都是黑色节点，有可能当我们给一个红色节点下插入一个红色节点时，会违背这条特征。 因此我们需要在插入黑色节点后进行结构调整，保证红黑树始终满足这 5 条特征。 红黑树插入后节点的调整思想 我们插入黑色节点的时候担心违背第5条，插入红色节点时担心违背第4条，所以我们将将插入的节点改为红色，然后判断插入的节点的父亲是不是红色，是的话进行修改调整（变色、左旋、右旋）。同时在调整的过程中我们需要遵守5条特性。 为什么要用红黑树？ 简单来说红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。详细了解可以查看 漫画：什么是红黑树？（也介绍到了二叉查找树，非常推荐） 推荐文章： 漫画：什么是红黑树？（也介绍到了二叉查找树，非常推荐） 寻找红黑树的操作手册（文章排版以及思路真的不错） 红黑树深入剖析及Java实现（美团点评技术团队） 二叉树的特点 只有一个根节点，每个非根节点只有一个父节点 叉树节点的子节点最多只能有两个 二叉树有左右之分 二叉树（百度百科） (1)完全二叉树——若设二叉树的高度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树，不需要填满二叉树，比如 (2)满二叉树——除了叶结点外，每一个结点都有左右子叶，且叶子结点都处在最底层的二叉树。 (3)平衡二叉树——平衡二叉树又被称为AVL树（区别于AVL算法），它是一棵二叉排序树，且具有以下性质：它是一棵空树，或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 二叉查找树（BST）具备什么特性呢？ 左子树上所有结点的值均小于或等于它的根结点的值。 右子树上所有结点的值均大于或等于它的根结点的值。 左、右子树也分别为二叉排序树。 缺陷：有可能会变成线性 下图中这棵树，就是一颗典型的二叉查找树： 堆 数据结构之堆的定义 堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。 如何快速建立一个平衡二叉树 平衡二叉树（百度百科，平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等 任意节点的左右子树的高度差都小于等于1。 找最低失衡节点，那就是找从最底层（叶子节点层）往最高层（root层）中最先出现左右子树高度差大于1的节点。 找替代节点就是找极值点，如果是左子树失衡，那就找左子树中的最大值，因为当左子树失衡时就表示我们不需要处理右子树，所以找到左子树的最大值，之后把右子树赋给该节点的右子节点即可。 同理，如果是右子树失衡那就找右子树中的最小值。 平衡二叉树的特点 任意节点的左右子树的高度差都小于等于1。 树的层序遍历 判断树是否左右对称或数组是否左右对称 Linux常用命令 目录切换命令 cd usr： 切换到该目录下usr目录 cd ..（或cd../）： 切换到上一层目录 cd /： 切换到系统根目录 cd ~： 切换到用户主目录 cd -： 切换到上一个操作所在目录 目录的操作命令(增删改查) mkdir 目录名称： 增加目录 ls或者ll（ll是ls -l的别名，ll命令可以看到该目录下的所有目录和文件的详细信息）：查看目录信息 find 目录 参数： 寻找目录（查） 示例： 列出当前目录及子目录下所有文件和文件夹: find . 在/home目录下查找以.txt结尾的文件名:find /home -name &quot;*.txt&quot; 同上，但忽略大小写: find /home -iname &quot;*.txt&quot; 当前目录及子目录下查找所有以.txt和.pdf结尾的文件:find . \\( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \\)或find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; mv 目录名称 新目录名称： 修改目录的名称（改） 注意：mv的语法不仅可以对目录进行重命名而且也可以对各种文件，压缩包等进行 重命名的操作。mv命令用来对文件或目录重新命名，或者将文件从一个目录移到另一个目录中。后面会介绍到mv命令的另一个用法。 mv 目录名称 目录的新位置： 移动目录的位置---剪切（改） 注意：mv语法不仅可以对目录进行剪切操作，对文件和压缩包等都可执行剪切操作。另外mv与cp的结果不同，mv好像文件“搬家”，文件个数并未增加。而cp对文件进行复制，文件个数增加了。 cp -r 目录名称 目录拷贝的目标位置： 拷贝目录（改），-r代表递归拷贝 注意：cp命令不仅可以拷贝目录还可以拷贝文件，压缩包等，拷贝文件和压缩包时不 用写-r递归 rm [-rf] 目录: 删除目录（删） 注意：rm不仅可以删除目录，也可以删除其他文件或压缩包，为了增强大家的记忆， 无论删除任何目录或文件，都直接使用rm -rf 目录/文件/压缩包 http状态码 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。（百度百科） 常见的状态码有200,301,302,304,404,500,403。 200：最常见，表示服务器响应成功，服务器找到了客户端请求的内容，并将内容发送给了客户端。 500：比较常见，表示程序错误，就是说请求的网页程序本身就报错了。现在的浏览器会对状态码500做出一定的处理，所以在一般情况下会返回一个定制的错误页面。 502：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效响应， 504：作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应 400：为包含语法错误，无法被服务器解析 403：为服务器已经接收请求，但是被拒绝执行 404：服务器上没有该资源，或者说是服务器上没有找到客户端请求的资源，是最常见的请求错误码。 301：临时跳转。url地址a可以向url地址b上跳转，但这并不意味着是永久性的，有可能过短时间就从url地址a跳转到地址c。 302：永久性的重定向。 304：被请求的资源内容没有发生更改。 tcp udp区别 运输层主要使用以下两种协议: 1. **传输控制协议 TCP**（Transmission Control Protocol）--提供**面向连接**的，**可靠的**数据传输服务。 2. **用户数据协议 UDP**（User Datagram Protocol）--提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。 UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等 TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。 三次握手四次挥手 三次握手过程： 客户端–发送带有 SYN 标志的数据包–一次握手–服务端 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端 当客户端和服务端通过三次握手建立了 TCP 连接以后，当数据传送完毕，断开连接就需要进行TCP的四次挥手。 四次挥手如下所示： 断开一个 TCP 连接则需要“四次挥手”： 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号 服务器-关闭与客户端的连接，发送一个FIN给客户端 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1 为什么建立连接是三次握手，关闭连接确是四次挥手呢？ 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 上面讲的比较概括，推荐一篇讲的比较细致的文章：https://blog.csdn.net/qzcsu/article/details/72861891 快排思路 快排的思想： 1.先从数组中取出一个数作为基准数；（第一个或者最后一个） 2.分区过程，将比这个数大的数全部放到它的右边，小于或等于它的数全部放到它的左边； 3.再对左右区间进行第二步，直到各区间只有一个数。 快排思路： 可以用补洞思路来实现上边的快排思想，简单来说就是挖洞之后，补洞。 挖一个洞来补洞，目的是要把数分到两边。 图一 图二 执行完毕后，比基准数小的在左边，比基准数大的在右边。因此对这两部分重复这个歌步骤就可以了。 注意： 1.洞在左边代表左边部分已经排好都是比基准数小的，洞在右边代表右边部分已经排好都是比基准数大的。 2.要补左边的洞从后往前比基准数小的，j递增；要补右边的洞从前往后比基准数大的，i递增。 作者：frankisbaby 链接：https://www.jianshu.com/p/f01c64fd2f93 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 1. 经典快速排序图示过程 (1) 经典快速排序的总体流程 (2) 根据基准值分区的过程 在[算法题] 荷兰国旗问题中有详细的介绍。 2. 随机快速排序 经典快速排序总是指定数组或者某部分的最后一个元素作为基准值，随机快速排序指定数组或者某一部分中的随机值作为基准值。 3. 动图展示 作者：CoderJed 链接：https://www.jianshu.com/p/a68f72278f8f 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 动画演示：https://github.com/lzever/animationSort 快慢指针问题 http1.0和 http1.1的区别及状态码 HTTP的特点： 支持客户端、服务器端模式，简单快速，客户端向服务器端请求服务时，只需传送请求方法和路径，灵活，HTTP允许传输任意类型的数据对象，无连接，限制每次连接只处理一个请求，无状态，HTTP协议是无状态协议，指明协议对于事务处理没有记忆能力。 HTTP都是由客户端发起请求的，并且由服务器端回应响应消息的。 灵活，我们知道允许可以任何类型的数据对象，包括音频，视频，图片，文件等等。 无状态，HTTP就是说，每次HTTP请求都是独立的，任何两个请求之间没有必然的联系。 无连接的，每次服务器在处理完客户端的请求后，并收到客户的应答后，就断开了通信，当客户端再次发送请求时就是一个新的连接，采用这种方式可以节省传输时间。 **这是HTTP/1.0版的主要缺点，**每个TCP连接只能发送一个请求，发送数据完毕后，连接就关闭了，如果还要请求就必须要新建一个请求连接。 HTTP是一种不保存状态，无状态协议，协议对于发送过来的请求或是响应都不做持久化处理。 HTTP1.1虽然是无状态协议，但是为了实现期望的保持状态功能，于是引入了Cookie技术，有了Cookie，和HTTP协议通信，就可以管理状态了。 TCP连接的新建成本很高，因为需要客户端和服务器端三次握手。 **交流的简单流程：**客户端发起连接，客户端发起请求，服务器端响应请求，服务器端关闭连接。 HTTP、1.1版本是最流行的版本，可以持久连接，TCP连接默认不关闭，可以被多个请求复用，只有在一段时间内，没有请求，就可以自动关闭。 HTTP1.0和HTTP1.1区别： 这部分回答引用这篇文章 https://www.jianshu.com/p/be29d679cbff 的一些内容。 长连接 : 在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 错误状态响应码 :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 缓存处理 :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用 :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 Host头处理，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。 延伸HTTP 2.0 HTTP2.0和HTTP1.X相比的新特性： 新的二进制格式（Binary Format），HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。 多路复用（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。 header压缩，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。 服务端推送（server push），同SPDY一样，HTTP2.0也具有server push功能。 HTTP2.0的升级改造 前文说了HTTP2.0其实可以支持非HTTPS的，但是现在主流的浏览器像chrome，firefox表示还是只支持基于 TLS 部署的HTTP2.0协议，所以要想升级成HTTP2.0还是先升级HTTPS为好。 当你的网站已经升级HTTPS之后，那么升级HTTP2.0就简单很多，如果你使用NGINX，只要在配置文件中启动相应的协议就可以了，可以参考NGINX白皮书，NGINX配置HTTP2.0官方指南 https://www.nginx.com/blog/nginx-1-9-5/。 使用了HTTP2.0那么，原本的HTTP1.x怎么办，这个问题其实不用担心，HTTP2.0完全兼容HTTP1.x的语义，对于不支持HTTP2.0的浏览器，NGINX会自动向下兼容的。 HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？ HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接； HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞； HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行； 具体如图： 为什么需要头部压缩？ 假定一个页面有100个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1kb的消息头（这同样也并不少见，因为Cookie和引用等东西的存在）, 则至少需要多消耗100kb来获取这些消息头。HTTP2.0可以维护一个字典，差量更新HTTP头部，大大降低因头部传输产生的流量。具体参考：HTTP/2 头部压缩技术介绍 HTTP2.0多路复用有多好？ HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。 HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。 http和https的区别 HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。 HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。 端口 ： HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。 安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等； 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。 redis缓存雪崩、缓存穿透、缓存击穿 1. 什么是缓存穿透？ 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。 2. 缓存穿透情况的处理流程是怎样的？ 如下图所示，用户的请求最终都要跑到数据库中查询一遍。 3. 有哪些解决办法？ 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。 1）缓存无效 key 如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。 另外，这里多说一嘴，一般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值 。 2）布隆过滤器 布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。 具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。 加入布隆过滤器之后的缓存处理流程图如下。 但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。 为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！ 我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 我们再来看一下，当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作： 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率） 更多关于布隆过滤器的内容可以看我的这篇原创：《不了解布隆过滤器？一文给你整的明明白白！》 ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。 1. 什么是缓存雪崩？ 我发现缓存雪崩这名字起的有点意思，哈哈。 实际上，缓存雪崩描述的就是这样一个简单的场景：缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。 举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。 还有一种缓存雪崩的场景是：有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下面几种解决办法： 举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。 2. 有哪些解决办法？ 针对 Redis 服务不可用的情况： 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。 针对热点缓存失效的情况： 设置不同的失效时间比如随机设置缓存的失效时间。 缓存永不失效。 分布式锁的实现方式 为何需要分布式锁 一般情况下，我们使用分布式锁主要有两个场景： 避免不同节点重复相同的工作：比如用户执行了某个操作有可能不同节点会发送多封邮件； 避免破坏数据的正确性：如果两个节点在同一条数据上同时进行操作，可能会造成数据错误或不一致的情况出现； Redis 分布式锁的问题 1）锁超时 假设现在我们有两台平行的服务 A B，其中 A 服务在 获取锁之后 由于未知神秘力量突然 挂了，那么 B 服务就永远无法获取到锁了： 所以我们需要额外设置一个超时时间，来保证服务的可用性。 但是另一个问题随即而来：如果在加锁和释放锁之间的逻辑执行得太长，以至于超出了锁的超时限制，也会出现问题。因为这时候第一个线程持有锁过期了，而临界区的逻辑还没有执行完，与此同时第二个线程就提前拥有了这把锁，导致临界区的代码不能得到严格的串行执行。 为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了问题，造成的数据小错乱可能就需要人工的干预。 有一个稍微安全一点的方案是 将锁的 value 值设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，这是为了 确保当前线程占有的锁不会被其他线程释放，除非这个锁是因为过期了而被服务器自动释放的。 但是匹配 value 和删除 key 在 Redis 中并不是一个原子性的操作，也没有类似保证原子性的指令，所以可能需要使用像 Lua 这样的脚本来处理了，因为 Lua 脚本可以 保证多个指令的原子性执行。 延伸的讨论：GC 可能引发的安全问题 Martin Kleppmann 曾与 Redis 之父 Antirez 就 Redis 实现分布式锁的安全性问题进行过深入的讨论，其中有一个问题就涉及到 GC。 熟悉 Java 的同学肯定对 GC 不陌生，在 GC 的时候会发生 STW(Stop-The-World)，这本身是为了保障垃圾回收器的正常执行，但可能会引发如下的问题： 服务 A 获取了锁并设置了超时时间，但是服务 A 出现了 STW 且时间较长，导致了分布式锁进行了超时释放，在这个期间服务 B 获取到了锁，待服务 A STW 结束之后又恢复了锁，这就导致了 服务 A 和服务 B 同时获取到了锁，这个时候分布式锁就不安全了。 不仅仅局限于 Redis，Zookeeper 和 MySQL 有同样的问题。 想吃更多瓜的童鞋，可以访问下列网站看看 Redis 之父 Antirez 怎么说：http://antirez.com/news/101 redis有哪些数据类型及其应用场景 1. string 介绍 ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。 常用命令: set,get,strlen,exists,dect,incr,setex 等等。 应用场景 ：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。 普通字符串的基本操作： 127.0.0.1:6379&gt; set key value #设置 key-value 类型的值 OK 127.0.0.1:6379&gt; get key # 根据 key 获得对应的 value &quot;value&quot; 127.0.0.1:6379&gt; exists key # 判断某个 key 是否存在 (integer) 1 127.0.0.1:6379&gt; strlen key # 返回 key 所储存的字符串值的长度。 (integer) 5 127.0.0.1:6379&gt; del key # 删除某个 key 对应的值 (integer) 1 127.0.0.1:6379&gt; get key (nil)Copy to clipboardErrorCopied 批量设置 : 127.0.0.1:6379&gt; mset key1 value1 key2 value2 # 批量设置 key-value 类型的值 OK 127.0.0.1:6379&gt; mget key1 key2 # 批量获取多个 key 对应的 value 1) &quot;value1&quot; 2) &quot;value2&quot;Copy to clipboardErrorCopied 计数器（字符串的内容为整数的时候可以使用）： 127.0.0.1:6379&gt; set number 1 OK 127.0.0.1:6379&gt; incr number # 将 key 中储存的数字值增一 (integer) 2 127.0.0.1:6379&gt; get number &quot;2&quot; 127.0.0.1:6379&gt; decr number # 将 key 中储存的数字值减一 (integer) 1 127.0.0.1:6379&gt; get number &quot;1&quot;Copy to clipboardErrorCopied 过期： 127.0.0.1:6379&gt; expire key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379&gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379&gt; ttl key # 查看数据还有多久过期 (integer) 56Copy to clipboardErrorCopied 2. list 介绍 ：list 即是 链表。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 LinkedList，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。 常用命令: rpush,lpop,lpush,rpop,lrange、llen 等。 应用场景: 发布与订阅或者说消息队列、慢查询。 下面我们简单看看它的使用！ 通过 rpush/lpop 实现队列： 127.0.0.1:6379&gt; rpush myList value1 # 向 list 的头部（右边）添加元素 (integer) 1 127.0.0.1:6379&gt; rpush myList value2 value3 # 向list的头部（最右边）添加多个元素 (integer) 3 127.0.0.1:6379&gt; lpop myList # 将 list的尾部(最左边)元素取出 &quot;value1&quot; 127.0.0.1:6379&gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) &quot;value2&quot; 2) &quot;value3&quot; 127.0.0.1:6379&gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) &quot;value2&quot; 2) &quot;value3&quot;Copy to clipboardErrorCopied 通过 rpush/rpop 实现栈： 127.0.0.1:6379&gt; rpush myList2 value1 value2 value3 (integer) 3 127.0.0.1:6379&gt; rpop myList2 # 将 list的头部(最右边)元素取出 &quot;value3&quot;Copy to clipboardErrorCopied 我专门花了一个图方便小伙伴们来理解： 通过 lrange 查看对应下标范围的列表元素： 127.0.0.1:6379&gt; rpush myList value1 value2 value3 (integer) 3 127.0.0.1:6379&gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) &quot;value1&quot; 2) &quot;value2&quot; 127.0.0.1:6379&gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) &quot;value1&quot; 2) &quot;value2&quot; 3) &quot;value3&quot;Copy to clipboardErrorCopied 通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！ 通过 llen 查看链表长度： 127.0.0.1:6379&gt; llen myList (integer) 3Copy to clipboardErrorCopied 3. hash 介绍 ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。 常用命令： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。 应用场景: 系统中对象数据的存储。 下面我们简单看看它的使用！ 127.0.0.1:6379&gt; hset userInfoKey name &quot;guide&quot; description &quot;dev&quot; age &quot;24&quot; OK 127.0.0.1:6379&gt; hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。 (integer) 1 127.0.0.1:6379&gt; hget userInfoKey name # 获取存储在哈希表中指定字段的值。 &quot;guide&quot; 127.0.0.1:6379&gt; hget userInfoKey age &quot;24&quot; 127.0.0.1:6379&gt; hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值 1) &quot;name&quot; 2) &quot;guide&quot; 3) &quot;description&quot; 4) &quot;dev&quot; 5) &quot;age&quot; 6) &quot;24&quot; 127.0.0.1:6379&gt; hkeys userInfoKey # 获取 key 列表 1) &quot;name&quot; 2) &quot;description&quot; 3) &quot;age&quot; 127.0.0.1:6379&gt; hvals userInfoKey # 获取 value 列表 1) &quot;guide&quot; 2) &quot;dev&quot; 3) &quot;24&quot; 127.0.0.1:6379&gt; hset userInfoKey name &quot;GuideGeGe&quot; # 修改某个字段对应的值 127.0.0.1:6379&gt; hget userInfoKey name &quot;GuideGeGe&quot;Copy to clipboardErrorCopied 4. set 介绍 ： set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。 常用命令： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。 应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景 下面我们简单看看它的使用！ 127.0.0.1:6379&gt; sadd mySet value1 value2 # 添加元素进去 (integer) 2 127.0.0.1:6379&gt; sadd mySet value1 # 不允许有重复元素 (integer) 0 127.0.0.1:6379&gt; smembers mySet # 查看 set 中所有的元素 1) &quot;value1&quot; 2) &quot;value2&quot; 127.0.0.1:6379&gt; scard mySet # 查看 set 的长度 (integer) 2 127.0.0.1:6379&gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素 (integer) 1 127.0.0.1:6379&gt; sadd mySet2 value2 value3 (integer) 2 127.0.0.1:6379&gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中 (integer) 1 127.0.0.1:6379&gt; smembers mySet3 1) &quot;value2&quot;Copy to clipboardErrorCopied 5. sorted set 介绍： 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。 常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。 应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。 127.0.0.1:6379&gt; zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重 (integer) 1 127.0.0.1:6379&gt; zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素 (integer) 2 127.0.0.1:6379&gt; zcard myZset # 查看 sorted set 中的元素数量 (integer) 3 127.0.0.1:6379&gt; zscore myZset value1 # 查看某个 value 的权重 &quot;3&quot; 127.0.0.1:6379&gt; zrange myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素 1) &quot;value3&quot; 2) &quot;value2&quot; 3) &quot;value1&quot; 127.0.0.1:6379&gt; zrange myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start 1 为 stop 1) &quot;value3&quot; 2) &quot;value2&quot; 127.0.0.1:6379&gt; zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop 1) &quot;value1&quot; 2) &quot;value2&quot; redis集群架构 Redis 主从复制 到 目前 为止，我们所学习的 Redis 都是 单机版 的，这也就意味着一旦我们所依赖的 Redis 服务宕机了，我们的主流程也会受到一定的影响，这当然是我们不能够接受的。 所以一开始我们的想法是：搞一台备用机。这样我们就可以在一台服务器出现问题的时候切换动态地到另一台去： 幸运的是，两个节点数据的同步我们可以使用 Redis 的 主从同步 功能帮助到我们，这样一来，有个备份，心里就踏实多了。 Redis 哨兵 后来因为某种神秘力量，Redis 老会在莫名其妙的时间点出问题 (比如半夜 2 点)，我总不能 24 小时时刻守在电脑旁边切换节点吧，于是另一个想法又开始了：给所有的节点找一个 &quot;管家&quot;，自动帮我监听照顾节点的状态并切换： 这大概就是 Redis 哨兵 (Sentinel) 的简单理解啦。什么？管家宕机了怎么办？相较于有大量请求的 Redis 服务来说，管家宕机的概率就要小得多啦.. 如果真的宕机了，我们也可以直接切换成当前可用的节点保证可用. Redis 集群化 好了，通过上面的一些解决方案我们对 Redis 的 稳定性 稍微有了一些底气了，但单台节点的计算能力始终有限，所谓人多力量大，如果我们把 多个节点组合 成 一个可用的工作节点，那就大大增加了 Redis 的 高可用、可扩展、分布式、容错 等特性： 上图 展示了 Redis Cluster 典型的架构图，集群中的每一个 Redis 节点都 互相两两相连，客户端任意 直连 到集群中的 任意一台，就可以对其他 Redis 节点进行 读写 的操作。 redis数据类型的底层数据结构 Redis 五种基本数据结构 redis为什么快，说一下io多路复用及 大体上来说，Redis 6.0 之前主要还是单线程处理。 那，Redis6.0 之前 为什么不使用多线程？ 我觉得主要原因有下面 3 个： 单线程编程容易并且更容易维护； Redis 的性能瓶颈不再 CPU ，主要在内存和网络； 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。 既然是单线程，那怎么监听大量的客户端连接呢？ Redis 通过IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。 这样的好处非常明显： I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。 另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件： 1. 文件事件; 2. 时间事件。 时间事件不需要多花时间了解，我们接触最多的还是 文件事件（客户端进行读取写入等操作，涉及一系列网络通信）。 《Redis 设计与实现》有一段话是如是介绍文件事件的，我觉得写得挺不错。 Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据 套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。 可以看出，文件事件处理器（file event handler）主要是包含 4 个部分： 多个 socket（客户端连接） IO 多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将 socket 关联到相应的事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） ","link":"https://ChicRingo.github.io/post/golang-mian-shi-ti/"}]}